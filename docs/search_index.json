[
["index.html", "Передмова 0.1 Теми:", " Передмова Ця книга про аналіз даних. Тут ми розглянемо основні питання статистики (описової та вивідної), візуалізації даних та машинного навчання. Це ще не остаточна версія. Якщо у вас є зауваження чи запитання напишіть мені. 0.1 Теми: Аналіз даних Основи теорії ймовірностей Описова статистика Вивідна статистика A/B тестування Машинне навчання "],
["introduction.html", "Розділ 1 Аналіз даних 1.1 Процес аналізу даних 1.2 Статистика 1.3 Дані 1.4 Рівні виміру 1.5 Матриця даних 1.6 Частотні таблиці 1.7 Центральна тенденція 1.8 Візуальний аналіз 1.9 Типи діаграм 1.10 Як обрати графік? 1.11 Трактування результатів", " Розділ 1 Аналіз даних Що потрібно знати, для того щоб займатись аналізом даних? Є три основні компоненти: 1) Знання предметної області. Це дозволяє розуміти, які проблеми потребують першочергового вирішення. 2) Знання математики та статистики. Вони дозволяють формалізувати рішення, перевести його в алгоритм та оцінити, яка ймовірність отримати результат. 3) Оскільки зараз є можливість застосовувати величезні обчислювальні потужності, тому вміння програмувати є важливим для побудови моделей. 1.1 Процес аналізу даних Складається з трьох етапів. Спочатку дані потрібно підготувати, тобто зібрати, очистити та відібрати ті, які потрібні для моделі. Цей процес займає близько 90% часу. Далі ми будуємо модель та валідуємо її результати. Останній етап – це презентація результатів. Тут ми демонструємо на яке питання ми шукали відповідь, які дані використовували та що отримали в результаті. Для того щоб це зробити максимально ефективно треба витрати ще 90% часу. 1.2 Статистика Davidian та Louis пропонують наступне визначення: “Statistics is the science of learning from data, and of measuring, controlling, and communicating uncertainty; and it thereby provides the navigation essential for controlling the course of scientific and societal advances” Davidian, M. and Louis, T. A., 10.1126/science.1218685. тобто Статистика - наука про навчання на основі даних, про вимірювання, контроль та тлумачення невизначеності; має важливе значення для управління ходом наукових і соціальних досягнень. Статистика допомагає оцінити варіативність та зменшити невизначеність. Розрізняють описову та вивідну статистики. Описова - вивчає властивості спостережуваних даних. Вивідна статистика – виводимо припущення про властивості розподілу даних з яких походять спостережувані дані З допомогою статистики можна дати відповідь на питання чи є залежність між кількістю злочинів та фазою Місяця? яка ймовірність викликати Uber в Києві? побудувати довірчий інтервал часу, за який ви потрапляєте на роботу проводити опитування та трактувати їх результати 1.3 Дані Кількісні: дискретні, неперервні Категоріальні: впорядковані, невпорядковані 1.4 Рівні виміру Точка Інтервал Відношення 1.5 Матриця даних Матриця даних – стартовий елемент для аналізу даних. Зазвичай йому передує етап збору, очищення та представлення у табличному вигляді. По рядках – респонденти, суб’єкти, учасники, спостереження По стовпцях - xарактеристики кожного запису(змінні). Також важливо звертати увагу на одиниці виміру а також яким чином були зібрані ці дані. Ця таблиця включає в себе 6 рядків, однак зібрані нами дані мають майже 800 спостережень(спостереження зібрані з ресурсу &lt;dom.ria.ua&gt; і містять інформацію про квартири, які продаються). Для того, щоб описати вміст цієї таблиці в більш зрозумілій формі використовують узагальнення та опис типових чи середніх значень. Для цього важливо знати тип даних. Місто Кімнат Загальна_площа Ціна Вінниця 3 120 1875000 Вінниця 3 66 975000 Вінниця 2 66 1375000 Вінниця 2 44 637500 Вінниця 3 63 835000 Вінниця 1 31 562500 1.6 Частотні таблиці Для узагальнення категоріальних даних використовують частотні таблиці. Ця таблиця містить кількість квартир, що продаються у кожному місті. Місто n Вінниця 275 Дніпропетровськ 18 Запоріжжя 13 Івано-Франківськ 47 Києво-Святошинський 19 Київ 186 Львів 16 Миколаїв 15 Одеса 43 Рівне 23 Тернопіль 93 Харків 14 Хмельницький 77 1.7 Центральна тенденція Опис центральної тенденції. Центральне або типове значення дозволяє зрозуміти основну характеристику даних 1.7.1 Середнє значення Середнє значення підходить для узагальнення кількісних даних(як дискретних, так і неперервних). Формула обрахування проста: \\[\\frac{\\sum_{i=1}^n X_i}{n}\\] Тобто ми суму всіх чисел, ділимо на їх кількість. Наприклад, якщо в нас є група з 5 учнів, оцінки яких 12, 3, 5, 10, 5. Сума їх оцінок дорівнює 35, а середнє значення 7. Однак із використанням середнього значення в якості опису центральної тенденції в даниї є невелика проблема. Якщо є нетипово великі чи малі для даного набору значення – вони роблять великий внесок у значення середнього. Нехай у нас є певне невелике підприємство, яке має 5 працівників. Заробітні плати працівників в гривнях: 5000, 7000, 2000, 4000, 50 000. Середнє значення заробітної плати 13600 грн. Однак, якщо ми відкинемо екстремальне значення 50 000, то отримаємо, що середнє значення зменшилося до 4500. 1.7.2 Медіана Медіана – це значення, яке ділить вибірку навпіл, тобто 50% є меншими за це значення, 50% більшими. Основна перевага використання медіани - менша чутливість до екстремальних значень. Для пошуку медіани, дані треба розташувати в зростаючому порядку та поділити на дві частини. Якщо в нас парна кількість спостережень то сусідні значення по краях сумуються та діляться на два. У випадку попереднього прикладу із заробіною платою: 2000, 4000, 5000, 7000, 50 000 Маємо, що посередині знаходиться значення 5000, то краще описує центральну тенденцію заробітної плати на підприємстві. Що робити, якщо дані не є кількісними? 1.7.3 Мода Мода використовується для визначення центральної тенденції категоріальних або кількісних дискретних даних. Мода - це значення, яке найчастіше трапляється. Наприклад, за інформацією міністерства юстиції України, минулого року хлопчиків найчастіше називали Дмитром, Артемом, Максимом та Іваном, дівчаток – Анею,Анастасією, Софією та Дар’єю. http://tyzhden.ua/News/137908 Ці імена є модою серед всіх імен. 1.8 Візуальний аналіз В 1848 в лондонському районі Сохо було зафіксовано спалах холери, під час якого загинуло 616 жителів. Під час цього спалаху Лікар епідеміолог Джон Сноу на основі візуального аналізу даних зробив припущення, що джерелом зараження є вода. https://en.wikipedia.org/wiki/John_Snow http://blog.rtwilson.com/john-snows-cholera-data-in-more-formats/ Проблема вакцинації та відмови від вакцинації актуальна не лише для України. Після опублікованого у 1998 році в британському медичному журналі дослідження де щеплення були вказані як причина аутизму кількість батьків, які відмовляються від щеплень збільшилась. Дослідення визнали помилковим, однак це не вплинуло на зростання кількості жителів США, які відмовлялися робити щепленння. Видання WSJ підготувало інтерактивні візуалізації, які відображають рівень захворюваності на кір, поліомієліт, кашлюк та інші хвороби до і після запровадження вакцини. Дані показують рівень захворюваності у США протягом 80 років http://graphics.wsj.com/infectious-diseases-and-vaccines/ 1.9 Типи діаграм 1.9.1 Стовпчкова діаграма Використовується для візуалізації категоріальних або кількісних дискретних даних. 1.9.2 Стовпчкова діаграма для двох змінних Маємо категоріальну змінну місто та дискретну змінну кількість кімнат. Залежно від того, чи нас цікавить розуміння внеску кожної категорії чи порівння категорій між собою вибираємо тип візуалізації. 1.9.3 Кругова діаграма Використовується для візуалізації категоріальних або кількісних дискретних даних з метою зрозуміти відношення складових до загального значення. Нехай ми аналізуємо дохід від продажу вина і хочемо зрозуміти частку кожного сорту в загальному продажі. Якщо ви захочете порівняти Caberne Sauvignon та Prosecco, то оцінити різницю між ними досить тяжко. Ці ж самі дані моджуть бути візуалізовані з допомогою стовпчикової діаграми: Де зрозуміло, що різниця між доходом від продажу Caberne Sauvignon та Prosecco складає приблизно 3%. Власне, популярна R бібліотека ggplot2 навіть не має фунціоналу для кругової діаграми. 1.9.4 Точкові графіки Кожна точка на графіку репрезентує одне спостереження. Тут ви бачите приклад не зовсім вдало підібраного графіку, оскільки візуалізується загальна площа квартир, що продаються. Загальна площа - неперервна кількісна змінна. Для її візуалізації краще використовувати гістограми. А точкові діаграми краще підходять для візуалізації дискретних даних. 1.9.5 Гістограма Використовується для оцінки форми розподілу кількісної змінної. На цьому графіку розподіл квартир, які продаються за загальною площею. Залежно від розміру інтервалу її форма може змінюватися. Наприклад змінимо інтервал з 25 метрів квадратних до 100: 1.9.6 Діаграма розсіювання Використовується для оцінки зв’язку двох кількісних змінних. 1.9.7 Лінійний графік Може використовуватись для оцінки зміни однієї чи кількох змінних у часі. Інформація Державної служби статистики https://ukrstat.org/uk/operativ/operativ2005/osv_rik/osv_u/vuz_u.html 1.10 Як обрати графік? При виборі типу графіка для візуалізації потрібно розуміти тип даних та що ви хочете зрозуміти. Порівнювати значення: стовпчикова діаграма, лінійний графік, графік розсіювання. Зрозуміти композицію(виділити складові): стовпчикова діаграма, кругова діаграма. Оцінити розподіл даних: лінійний графік, графік розсіювання, стовпчикова діаграма, гістограма. Зрозуміти тренд: лінійний графік, стовпчикова діаграма. Зрозуміти відношення між даними: лінійний графік, графік розсіювання. 1.11 Трактування результатів Трактування результатів чи не найважливіша частина дослідження. Невірне трактування результатів дослідження дозволяє здійснювати маніпуляції. Детальніше про це можна прочитати у книзі Darell Huff “How to Lie with Statistics”, яка була видана ще в 1954 році. Однак, іноді складається ситуація, що й правильне дослідженне може мати двояке трактування. 1.11.1 Парадокс Сімпсона Парадокс Сімпсона названо на честь дослідника Едварда Сімпсона, який у 1951 описав цей феномен. Хорошою ілюстрацією буде ситуація, що склалася в університеті Берклі в 1973. Тоді університет звинуватили в гендерній нерівності. Для ілюстрації ми дещо спростимо вихідні умови. Нехай в університеті є всього два факультети: A та В. Факультет А подало_заяв прийнято відсоток_прийнятих чоловіки 900 450 50 жінки 100 80 80 Факультет B подало_заяв прийнято відсоток_прийнятих чоловіки 100 10 10 жінки 900 180 20 Якщо ми подивимось на відсоток прийнятих окремо по факультетах A та B то можемо зробити висновок, що дискріминують чоловіків. Однак, якщо об’єднати результати кількості прийнятих по факультетах, то ситуація виявиться зовсім іншою: Разом факультети А та В подало_заяв прийнято відсоток_прийнятих чоловіки 1000 460 46 жінки 1000 260 26 Тут вже можна припускати факт наявності дискримінації жінок. Візуалізацію повної версії можна переглянути тут: http://vudlab.com/simpsons/ "],
["rrstudio.html", "Розділ 2 Робота з R/Rstudio 2.1 R як калькулятор: 2.2 Типи даних в R: 2.3 Типи R обєктів", " Розділ 2 Робота з R/Rstudio Встановлення R: перейдіть за посиланням https://cloud.r-project.org/ оберіть вашу операційну систему завантажте відповідний пакунок інсталюйте його Встановлення RStudio: перейдіть за посиланням https://www.rstudio.com/products/rstudio/download/ оберіть вашу операційну систему завантажте відповідний пакунок інсталюйте його Створити новий файл в RStduio: в меню обрати пункт меню File далі New File обрати пункт RScript R має модульну структуру. Ви встановлюєте базовий функціонал і розширяєте його потрібними вам бібліотеками. Зараз у репозиторії CRAN наличується ~ 7000 бібліотек. Для встановлення бібліотеки використовується команда install.packages Скопіюйте у R файл ці команди: install.packages(&#39;dplyr&#39;, dependencies = TRUE) install.packages(&#39;ggplot2&#39;, dependencies = TRUE) Щоб виконати код, виділіть рядки та натисніть піктограму Run з зеленою стрілкою або комбінацію клавіш CTRL + ENTER або COMMAND + ENTER. Також код можна набирати в консолі(нижня ліва панель в RStudio). Для завантаження в робоче середовище команда library. Далі завантажте ці бібліотеки до вашого робочого середовища. Це можна зробити з допомогою функції library. Зауважте, що ми встановлюємо бібліотеку один раз, але завантажувати її потрібно щоразу, як ви перезапускаєте RStudio. Тобто при наступному запуску RStudio команди інсталяції не будуть потрібні і їх можна буде закоментувати використовуючи символ #: 2.1 R як калькулятор: 2+3-8 # додавання та віднімання ## [1] -3 7*5/2 # множення та ділення ## [1] 17.5 pi # константа пі ## [1] 3.141593 sqrt(4) # корінь квадратний ## [1] 2 2^3 # піднесення до степеня ## [1] 8 Символ присвоєння: &lt;- # x присвоїти значення 2 x &lt;- 2 # вивести значення x x ## [1] 2 x та X - різні змінні X &lt;- 3 X ## [1] 3 x ## [1] 2 2.2 Типи даних в R: Логічні - TRUE, FALSE Стрічкові - character Числові - numeric, integer, double, complex На відміну від мов Java чи C в R не обов’язково декларувати тип змінної. Дізнатися тип має змінна можна з допомогою функції class v1 &lt;- TRUE class(v1) ## [1] &quot;logical&quot; v1 &lt;- -10.6 class(v1) ## [1] &quot;numeric&quot; v1 &lt;- 3L # L вказує що це ціле число class(v1) ## [1] &quot;integer&quot; v1 &lt;- 3+2i class(v1) ## [1] &quot;complex&quot; v1 &lt;- &quot;stats&quot; class(v1) ## [1] &quot;character&quot; 2.3 Типи R обєктів Вектор Матриця Список(list) Фактор Таблиця даних(data frame) Вектор - набір значень одного типу. Утворюється з допомогою функції c (скорочення від concatenate). numeric_vector &lt;- c(1, 10, 49) boolean_vector &lt;- c(TRUE, FALSE, TRUE) character_vector&lt;- c(&quot;Monday&quot;, &quot;Tuesday&quot;, &quot;Wednesday&quot;, &quot;Thursday&quot;, &quot;Friday&quot;) Операції з векторами: x &lt;- c(10, 2, 3, 7, 4) y &lt;- c(2, -1, 3, 2, 6) # додавання/віднімання # додаються/віднімаються поелементно x + y ## [1] 12 1 6 9 10 x - y ## [1] 8 3 0 5 -2 # множення на скаляр 2*x ## [1] 20 4 6 14 8 # застосування функції до кожного елемента sqrt(x) ## [1] 3.162278 1.414214 1.732051 2.645751 2.000000 # сума елементів sum(x) ## [1] 26 # довжина вектора length(x) ## [1] 5 # об&#39;єданання векторів z &lt;- c(x, y) z ## [1] 10 2 3 7 4 2 -1 3 2 6 Доступ до елементів вектора. x &lt;- 1:20 # інший спосіб задання вектора, вказуємо послідовність від 1 до 20 x ## [1] 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 # п&#39;ятий елемент(відлік починається з одиниці) x[5] ## [1] 5 # елементи з 6 по 12 x[6:12] ## [1] 6 7 8 9 10 11 12 # елементи 6, 10, 13 x[c(6, 10, 13)] ## [1] 6 10 13 # елементи за винятком 6 та 13 x[-c(6, 13)] ## [1] 1 2 3 4 5 7 8 9 10 11 12 14 15 16 17 18 19 20 # елементи, які більше 5 x[x &gt; 5] ## [1] 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 # елементи, які більше 5 і менші 15 x[x &gt; 5 &amp; x &lt; 15] ## [1] 6 7 8 9 10 11 12 13 14 # елементи, які менші 5 або більші 15 x[x &lt; 5 | x &gt; 15] ## [1] 1 2 3 4 16 17 18 19 20 Відсутні значення (аналог null) позначаються як NA (Not avaliable). Впливають на результат обчислень. x &lt;- c(10, 20, NA, 4, NA, 2) sum(x) ## [1] NA sum(x, na.rm = TRUE) ## [1] 36 Матриця - по суті двовимірний вектор mat &lt;- matrix(data=c(9,2,3,4,5,6),ncol=3) mat ## [,1] [,2] [,3] ## [1,] 9 3 5 ## [2,] 2 4 6 Список (list). Якщо елементи вектора мають бути одного типу, то елементи списку можуть мати різні типи. a &lt;- list(p_name=&quot;Joe&quot;, 4, foo=c(3,8,9)) print(a) ## $p_name ## [1] &quot;Joe&quot; ## ## [[2]] ## [1] 4 ## ## $foo ## [1] 3 8 9 Доступ до елементів з використанням символа [[]] або $ та імені(якщо елемент має ім’я) a[[3]] ## [1] 3 8 9 a[[1]] ## [1] &quot;Joe&quot; a$p_name ## [1] &quot;Joe&quot; Фактор - вектор для збереження категоріальних даних. Може містити як категоріальні впорядковані, так і категоріальні невпорядковані дані. Нехай маємо звичайний вектор: mons &lt;- c(&quot;March&quot;,&quot;April&quot;,&quot;January&quot;,&quot;November&quot;,&quot;January&quot;,&quot;September&quot;,&quot;October&quot;,&quot;September&quot;,&quot;November&quot;,&quot;August&quot;, &quot;January&quot;,&quot;November&quot;,&quot;November&quot;,&quot;February&quot;,&quot;May&quot;,&quot;August&quot;,&quot;July&quot;,&quot;December&quot;,&quot;August&quot;,&quot;August&quot;,&quot;September&quot;, &quot;November&quot;,&quot;February&quot;,&quot;April&quot;) class(mons) ## [1] &quot;character&quot; Створимо впорядкований фактор, в параметрі level задамо та задамо порядок: mons &lt;- factor(mons,levels=c(&quot;January&quot;,&quot;February&quot;,&quot;March&quot;,&quot;April&quot;,&quot;May&quot;,&quot;June&quot;,&quot;July&quot;,&quot;August&quot;,&quot;September&quot;, &quot;October&quot;,&quot;November&quot;,&quot;December&quot;),ordered=TRUE) class(mons) ## [1] &quot;ordered&quot; &quot;factor&quot; Тепер можемо визначити, чи March &lt; April mons[1] ## [1] March ## 12 Levels: January &lt; February &lt; March &lt; April &lt; May &lt; June &lt; ... &lt; December mons[2] ## [1] April ## 12 Levels: January &lt; February &lt; March &lt; April &lt; May &lt; June &lt; ... &lt; December mons[1] &lt; mons[2] ## [1] TRUE Дата фрейм (data frame) використовується для роботи з таблицями. Є три способи створити data frame. Об’єднати вектори однакової довжини, використовуючи команду data.frame cause &lt;- c(&#39;pilot error&#39;, &#39;mechanical&#39;, &#39;weather&#39;, &#39;sabotage&#39;, &#39;other&#39;) amount &lt;- c(640, 195, 63, 95, 111) plane_crash &lt;- data.frame(cause, amount) Використовувати вбудовані набори даних head(airquality) ## Ozone Solar.R Wind Temp Month Day ## 1 41 190 7.4 67 5 1 ## 2 36 118 8.0 72 5 2 ## 3 12 149 12.6 74 5 3 ## 4 18 313 11.5 62 5 4 ## 5 NA NA 14.3 56 5 5 ## 6 28 NA 14.9 66 5 6 Зчитати з файла (розглянемо в лабораторній) Базові операції # кількість стовпців ncol(airquality) ## [1] 6 # кількість рядків nrow(airquality) ## [1] 153 # назви колонок colnames(airquality) ## [1] &quot;Ozone&quot; &quot;Solar.R&quot; &quot;Wind&quot; &quot;Temp&quot; &quot;Month&quot; &quot;Day&quot; # вcі дані для 5 місяця airquality2 &lt;- airquality[airquality$Month == 5, ] head(airquality2) ## Ozone Solar.R Wind Temp Month Day ## 1 41 190 7.4 67 5 1 ## 2 36 118 8.0 72 5 2 ## 3 12 149 12.6 74 5 3 ## 4 18 313 11.5 62 5 4 ## 5 NA NA 14.3 56 5 5 ## 6 28 NA 14.9 66 5 6 # температура для 5 місяця airquality$Temp[airquality$Month == 5] ## [1] 67 72 74 62 56 66 65 59 61 69 74 69 66 68 58 64 66 57 68 62 59 73 61 ## [24] 61 57 58 57 67 81 79 76 "],
["centraltendency.html", "Розділ 3 Центральна тенденція 3.1 Квартилі та інтерквартильний розмах. 3.2 Коробчата діаграма 3.3 Дисперсія та середньоквадратичне відхилення", " Розділ 3 Центральна тенденція Матриця(таблиця) даних – стартовий елемент для аналізу даних. Зазвичай йому передує етап збору, очищення та представлення у табличному вигляді. По рядках – респонденти, суб’єкти, учасники, спостереження По стовпцях - xарактеристики кожного запису(змінні). Також важливо звертати увагу на одиниці виміру а також яким чином були зібрані ці дані. Приклад таблиці: Місто Кімнат Загальна_площа Ціна Вінниця 3 120 1875000 Вінниця 3 66 975000 Вінниця 2 66 1375000 Вінниця 2 44 637500 Вінниця 3 63 835000 Вінниця 1 31 562500 Спостереження зібрані з ресурсу https://dom.ria.com/ і містять інформацію про квартири, які продаються. Будемо детальніше аналізувати цей датасет в лабораторній роботі. Минулого тижня ми розглянули опис центральної тенденції. Залежно від даних, в якості центральної тенденції використовується середнє значення, медіана або мода Середнє значення підходить для узагальнення кількісних даних(як дискретних, так і неперервних). Формула обрахування проста: \\[\\frac{\\sum_{i=1}^n X_i}{n}\\] Тобто ми суму всіх чисел, ділимо на їх кількість. Наприклад, якщо в нас є група з 5 учнів, оцінки яких 12, 3, 5, 10, 5. Сума їх оцінок дорівнює 35, а середнє значення 7. Однак із використанням середнього значення в якості опису центральної тенденції в даниї є невелика проблема. Якщо є нетипово великі чи малі для даного набору значення – вони роблять великий внесок у значення середнього. Нехай у нас є певне невелике підприємство, яке має 5 працівників. Заробітні плати працівників в гривнях: 5000, 7000, 2000, 4000, 50 000. Середнє значення заробітної плати 13600 грн. Однак, якщо ми відкинемо екстремальне значення 50 000, то отримаємо, що середнє значення зменшилося до 4500. Медіана – це значення, яке ділить вибірку навпіл, тобто 50% є меншими за це значення, 50% більшими. Основна перевага використання медіани - менша чутливість до екстремальних значень. Для пошуку медіани, дані треба розташувати в зростаючому порядку та поділити на дві частини. Якщо в нас парна кількість спостережень то сусідні значення по краях сумуються та діляться на два. У випадку попереднього прикладу із заробіною платою: 2000, 4000, 5000, 7000, 50 000 Маємо, що посередині знаходиться значення 5000, то краще описує центральну тенденцію заробітної плати на підприємстві. Мода - значення, яке найчастіше трапляєтться. Може використовуватись як для категоріальних, так і для кількісних даних. Дані можуть мати кілька мод, а можуть не мати жодної. 3.1 Квартилі та інтерквартильний розмах. Якщо медіана ділить дані порівну, то квартилі ділять їх на чотири частини. Вони позначаються Q1, Q2, Q3, Q4. Q1 - 25% Q2 - 50% (співпадає з медіаною) Q3 - 75% Q4 - 100% Інтерквартильний розмах(IQR) = Q3 - Q1 Нехай маємо ряд 62, 81, 63, 77, 64, 81, 64, 70, 72, 76. Спочатку відсортуємо дані в зростаючому порядку: 62, 63, 64, 64, 70, 72, 76, 77, 81, 81. Медіана(та Q2)): \\(\\frac{70+72}{2} = 71\\) Для обрахунку Q1 та Q3 значення медіани включаються до інтервалу. Q1: \\(\\frac{64 + 64 }{2} = 64\\) Q3: \\(\\frac{76 + 77 }{2} = 76.5\\) Інтерквартильний розмах(ІКР): Q3 - Q1 = 76.5 - 64 = 12.5 Середнє, мода та медіана є описовими статистиками. Також виділяють узагальнення п’яти чисел (five numbers summary). Воно включає в себе: Найменше значення Перший квартиль Медіана (другий квартиль) Третій квартиль Найбільше значення Узагальнення п’яти чисел для ряду можна отримати використовуючи R функцію summmary. summary(c(62, 81, 63, 77, 64, 81, 64, 70, 72, 76)) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 62.00 64.00 71.00 71.00 76.75 81.00 Наприклад, застосуємо цю статистику для оцінки довжини анаконд (завантажити набір даних можна за посиланням http://www.public.iastate.edu/~maitra/stat501/datasets/anaconda.dat): anaconda &lt;- read.table(&quot;anaconda.dat&quot;) summary(anaconda$V1) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 172.0 229.3 258.8 288.5 333.0 477.0 quantile(anaconda$V1) ## 0% 25% 50% 75% 100% ## 172.000 229.350 258.750 332.975 477.000 3.2 Коробчата діаграма Дозволяє візуалізувати yзагальнення п’яти чисел та знайти нетипові дані(так звані “викиди”) “Викид” (outlier) - значення, яке знаходиться на відстані, меньшій ніж 1.5 ІКР від Q1 або більшій від Q3. Якщо ми хочемо детальніше оцінити розподіл довжини анаконд, можемо використати гістограму: ggplot(anaconda, aes(x=V1)) + geom_histogram(breaks=seq(0, 500, by = 50),fill=&quot;lightblue&quot;, col=&quot;grey&quot;) + xlab(&quot;Довжина анаконди&quot;) + ylab(&quot;Кількість спостережень&quot;) 3.3 Дисперсія та середньоквадратичне відхилення Середньоквадратичне відхилення(standard deviation) дає розуміння, наскільки далеко знаходиться типове спостереження від середнього значення. Дисперсія(variance) - обчислюється як середнє значення відстаней від всіх спострежень до середнього значення у квадраті. \\[var =\\frac{\\sum\\limits_{i=1}^{N}(x_{i} - \\mu)^2} {N}\\] Середньоквадратичне відхилення(standard deviation) \\(\\sigma\\)- обчислюється як корінь квадратний з дисперсії. \\[\\sigma =\\sqrt{\\frac{\\sum\\limits_{i=1}^{N}(x_{i} - \\mu)^2} {N}}\\] Давайте обрахуємо дисперсію та середньоквадратичне відхилення. Нехай у нас є ряд: 5, 3, 2, 8, 2. Середнє значення \\(\\mu = 4\\). Обчислимо дисперсію та середньоквадратичне відхилення: Дисперсія: \\[var = \\frac{(5-4)^2+(3-4)^2+(2-4)^2+(8-4)^2+(2-4^2)}{5} = \\frac{1^2 + (-1)^2+(-2)^2+4^2+(-2)^2 }{5} = \\frac{1+1+4+16+4}{5}=5.2\\] Середньоквадратичне відхилення: \\[\\sigma = \\sqrt{var} = 2.28\\] Дисперсія для ряду 3, 5, 5, 3, 4, середнє значення якого теж 4: \\[var = \\frac{(3-4)^2+(5-4)^2+(5-4)^2+(3-4)^2+(4-4^2)}{5} = \\frac{(-1)^2 + 1^2+1^2+ (-1)^2+(0)^2 }{5} = \\frac{4}{5}=0.8\\] Середньоквадратичне відхилення: \\[\\sigma = \\sqrt{var} = 0.89\\] Якщо поглянути на обидва ряди, бачимо що значення другого більш тісно розташовані навколо середнього. Значення дисперсії та середньоквадратичного дозволяють це виразити чисельно. Приклад: Степан має 800 друзів у Facebook, Аня 1000 послідовників в Instagram. Хто більш популярний? Для відповіді на це питання нам потрібні будуть дані про середнє значення та середньоквадратичне відхилення для кількості друзів у Facebook та послідовників у Instagram. Facebook: середнє значення \\(\\mu = 649\\), середньоквадратичне відхилення \\(\\sigma = 50\\) Instagram: середнє значення \\(\\mu =843\\), середньоквадратичне відхилення \\(\\sigma =60\\) Обчислимо відстань до середнього значення в середньоквадратичних відхиленнях: Степан: \\[ \\frac{x - \\mu}{\\sigma} = \\frac{800 - 649}{50} = 3.02\\]. Аня: \\[ \\frac{x - \\mu}{\\sigma} = \\frac{1000 -843}{60} = 2.61\\]. Можемо вважати, що Степан більш популярний, оскільки значення кількості його друзів знаходиться далі від середнього значення. Процес перетворення даних з допомогою формули \\(\\frac{x - \\mu}{\\sigma}%\\) має назву z-стандартизація, а отримані значення - z-значення. Наступного тижня розглянемо застосування z-значень для оцінки ймовірності. "],
["probability.html", "Розділ 4 Ймовірність 4.1 Ймовірність однієї події 4.2 Ймовірність кількох подій 4.3 Теорема Байеса 4.4 Класичні розподіли 4.5 Нормальний розподіл 4.6 Коваріація та кореляція 4.7 Лінійна регресія", " Розділ 4 Ймовірність 4.1 Ймовірність однієї події Розглянемо класичний приклад із підкиданням монетки. Коли ми підкидаємо монетку, ми не можемо сказати “орлом” чи “решкою” вона впаде. Підкидання монетки - випробування. Випробування (експеримент) – сукупність умов, за яких спостерігається певне явище чи результат. Результатом у прикладі з монеткою є факт, що монетка впала “орлом” або “решкою”. Випадання “орла” чи “решки” - подія. Подія – факт, який в результаті експерименту може відбутись чи не відбутись.Якщо ми будемо підкидати цю монетку велику кількість раз(наприклад тисячу) і щоразу записувати результат, то зможемо оцінити ймовірність настання кожної події. Ймовірність – чисельна міра впевненості в появі даної події внаслідок нового випробування. Тобто, якщо нас цікавить, яка ймовірність випадання “решки” для даної монетки, то ми підкидаємо монетку n разів та обчислюємо ймовірність p(A) за формулою \\[p(A) =\\frac {m}{n}\\] де A - подія “монета впала решкою” p(A) - ймовірність цієї події m - кількість разів, коли настала подія A n - кількість випробувань Оскільки m та n - цілі числа і 0 ≤ m ≤ n, то 0 ≤ P(A) ≤ 1. Закон великих чисел стверджує, що якщо ми будемо повторювати експеримент нескінченну кількість разів(на практиці просто достатньо багато), то частка настання нашої події до кількості випадків буде наближатися до реальної ймовірності настання цієї події. На графіку ви бачите, як змінюється ймовірність випадання орла p в залежності від кількості спроб: ## [1] 0 Таке трактування ймовірності має назву “частотна інтерпретація” і передбачає, що випробування можна здійснити достатньо велику кількість разів. Існує інший підхід до визначення ймовірності, так звана “байесівська інтерпретація”. Вона передбачає, що в нас є якась початкова ймовірність, наприклад корумпованості конкретного чиновника, і ми коригуємо цю ймовірність в залежності від фактів (для чиновника це можуть бути подані декларації, нерухоме майно). Сума ймовірностей всіх можливих подій, які можуть настати в результаті випробування(для монети це випадання орлом або решкою) дорівнює одиниці. 4.2 Ймовірність кількох подій Щоб оцінити ймовірність настання кількох подій, потрібно зрозуміти, як вони співвідносяться між собою. Події можуть бути: Несумісні(disjoint) - не можуть відбуватись одночасно. Приклад несумісних подій: монета не може впасти і орлом і решкою не можна здати і провалити іспит одночасно Відповідно, якщо для обчислення ймовірністі настання події A або події B, які є несумісними, використаємо формулу: P(A or B) = P(A) + P(B) Сумісні(joint) - можуть відбуватись одночасно. Студент може одночасно проходити курс статистики та англійської мови. Це приклад сумісних подій, де подія A - проходить курс статистики, подія B - проходить курс англійської мови. Формула, для визначення ймовірністі настання події A або події B, якщо події є сумісними: P(A or B) = P(A) + P(B) – P (A and B) Розглянемо приклад: Було опитано 77882 людини з 57 країн світу. 36.2% погоджуються з твердженням “Чоловіки повинні мати більше прав ніж жінки”. 13.8% мають університетську освіту. 3.6% належать до обох категорій. Яка ймовірність, що випадковим чином обрана людина має вищу освіту або погоджується з твердженням “Чоловіки повинні мати більше прав ніж жінки”? Події “випадковим чином обрана людина має університетську освіту” та “випадковим чином обрана людина погоджується з твердженням” є сумісними. Тому для обчислення ймовірністі, що випадковим чином обрана людина з вищою освітою або погоджується з твердженням скористаємось формулою додавання ймовірностей для сумісних подій: P(A or B) = P(A) + P(B) – P (A and B) Тобто P(A or B) = 36.2% + 13.8% - 3.6% = 46.4% Дві події є незалежними(independent), якщо знання про настання однієї з них не дає можливості оцінити ймовірність настання іншої. Для прикладу, знання того, що надворі йде дощ не дає нам додаткової інформації для оцінки ймовірності виграти в лотереї. Для обрахування ймовірності настання одночасно незалежних подій A та B використовуємо формулу: P(A and B) = P(A) x P(B) Буває ситуація, коли події залежать одна від одної. Наприклад, у дощовий день ймовірність викликати таксі зменшується. Такі ймовірності називають умовними(conditional). Можемо записати це так: P(викликали таксі | дощ) = 0.4 P(викликали таксі |\\(\\neg\\)дощ) = 0.8 Де знак \\(\\neg\\) означає заперечення. Крім того, також є ймовірність дощу в конкретному місті. Така ймовірність називається апріорною. Нехай ймовірність дощу в цьому місті дорівнює 0.7. Тоді, відповідно, \\(\\neg\\)дощ = 0.3. Для умовних ймовірностей ймовірність одночаного настання подій A та B обчислюється за формулою P(A and B) = P(A|B) * P(B) Якщо ми хочемо обчислити ймовірність викликати таксі, то спочатку оцінимо ймовірність викликати таксі, коли йде дощ і ймовірність цієї події, коли дощу нема. A - викликали таксі B - дощ Використавши формулу P(A and B) = P(A|B) * P(B) маємо: P(викликали таксі) = P(викликали таксі і дощ) + P(викликали таксі і \\(\\neg\\)дощ) = P(викликали таксі | дощ) x P(дощ) + P(викликали таксі | \\(\\neg\\)дощ) x P(\\(\\neg\\)дощ) = 0.4x0.7 + 0.8x0.3 = 0.28 + 0.24 = 0.52 4.3 Теорема Байеса Теорема Байеса названа на честь проповідника вісімнадцятого сторіччя Томаса Байеса. Теорема має багато застосувань і вважається головною теоремою статистики. Теорема Байеса(її ще називають правилом Байеса): \\[ P(A \\mid B) = \\frac{P(B \\mid A) \\, P(A)}{P(B)} \\] A та B - події P(B) &gt; 0 P(A \\(\\mid\\) B) ймовірність настання події A, якщо відбулася подія B P(B \\(\\mid\\) A) ймовірність настання події B, якщо відбулася подія A Розглянемо це на прикладі: В 2009 році в найвищий відсоток захворюваності на ВІЛ/СНІД було зафіксовано в Свазіленді і становить 25.9% Тест ELISA один з найкращих та найточніших тестів. Для тих, хто хворий на СНІД тест має точність 99.7%, для тих хто не хворий 92.6%. Якщо за результатами тесту людина ВІЛ інфікована, яка ймовірність що вона дійсно хвора? P(хвора) = 0.259 - пріорна можливість захворіти P(тест +| хвора) = 0.997 - ймовірність. що тест покаже позитивний результат, якщо людина хвора P(тест -|нe хвора) = 0.926 ймовірність. що тест покаже негативний результат, якщо людина здорова Потрібно оцінити ймовірність що вона дійсно хвора, якщо тест показав позитивний результат, тобто P(хвора | тест +). За теоремою Байеса: \\[P(хвора \\mid тест+) = \\frac {P(тест+ \\mid хвора)P(хвора) } {P(тест +)}\\] Для обрахунку, нам не вистачає лише інфомації яка ймовірність, що тест дасть позитивний результат для будь-якого жителя(чи жительки) Свазіленда. P(тест +) = P(тест+ і хвора) + P(тест+ і \\(\\neg\\)хвора) = P(тест+ \\(\\mid\\) хвора)P(хвора) + P(тест+ \\(\\mid\\) \\(\\neg\\)хвора)P(\\(\\neg\\)хвора) P(\\(\\neg\\)хвора) = 1 - P(хвора) = 0.741 P(тест + \\(\\mid\\) \\(\\neg\\)хвора) = 1 - P(тест- \\(\\mid \\neg\\)нe хвора) = 1 - 0.926 = 0.074 P(тест+) = 0.997x0.259 + 0.074x0.741 = 0.2582 + 0.0548 = 0.313 \\[P(хвора \\mid тест+) = \\frac {P(тест+ \\mid хвора)P(хвора) } {P(тест +)} = \\frac{0.997*0.259}{0.313} = 0.825\\] Для знаходження ймовірностей можемо скористись візуалізацією: 4.4 Класичні розподіли Якщо ми знаємо, що наші дані належать до якогось з класичних розподілів, то можемо використати вже вивчені властивості цих розподілів. Є дискретні та неперервні класичні розподіли. Як приклад дискретного розглянемо біноміальний, а як приклад неперервного - нормальний розподіл. Біноміальний розподіл - дискретний розподіл, тобто розподіл величини, яка може набирати фіксованих значень. Уявіть собі підкидання монетки 5 разів. Монета може випасти орлом 0, 1, 2, 3, 4 або 5 разів, але не 0.67 чи 3.57. Відповідно змінна, яка описує кількість разів, які монета впала орлом є дискретною змінною. Біноміальний розподіл підходить для опису розподілу даних, де результати, можуть набирати лише двох можливих значень (від виходу з ладу деталей машин до студентів, які здають іспит). Події в біноміальному розподілі генеруються внаслідок процесу Бернуллі. Одне випробування в процесі Бернуллі має назву випробування Бернуллі. Коли кожне випробування має лише два можливих наслідки. Ці наслідки класифікуються як “успіх” чи “невдача”. “Успіх” - не обов’язково має позитивний контекст. Наприклад, “успіхом” може бути наслідок “вихід з ладу важливої деталі”. Розглянемо біноміальний розподіл на прикладі експеримента Мілґрема https://uk.wikipedia.org/wiki/%D0%95%D0%BA%D1%81%D0%BF%D0%B5%D1%80%D0%B8%D0%BC%D0%B5%D0%BD%D1%82_%D0%9C%D1%96%D0%BB%D2%91%D1%80%D0%B5%D0%BC%D0%B0. Експеримент почався в липні 1961, через три місяці після того, як почався процес над нацистським військовим злочинцем Адольфом Ейхманом в Єрусалимі. Мілґрем задумав експеримент, щоб дати відповідь на питання: “Чи міг Ейхман і мільйони його спільників по Голокосту просто виконувати накази? Чи можемо ми їх всіх називати спільниками?” Експериментатор (E) вимагав від “вчителя” (T) давати #учневі&quot; (L) прості завдання на запам’ятовування і при кожній помилці “учня” натискати на кнопку, нібито карає його ударом струму (насправді актор, що грав “учня”“, тільки вдавав, що отримує удари). Почавши з 15 вольт,”вчитель&quot; з кожною новою помилкою повинен був збільшувати напругу на 15 вольт (верхня допустима межа в експерименті 450 вольт). В одній серії дослідів основного варіанту експерименту 26 досліджуваних з 40, замість того щоб змилосердитися над жертвою, продовжували збільшувати напругу (до 450 В) до тих пір, поки дослідник не віддавав розпорядження закінчити експеримент (інформація взята з wikipedia). Будемо розглядати кожну особу в експерименті Мілгрема як випробування. Успіхом будемо вважати подію, коли особа відмовилась продовжувати експеримент, невдачею- якщо погодилась Оскільки 35%(14 із 40) відмовляється то ймовірність успіху в одній спробі 35%. Якщо ми виберемо для експерименту трьох випадкових людей, яка ймовірність що один з них відмовиться? Назвемо цих людей Антон, Богдан та Вікторія. Якщо відмовиться Антон, то цей варіант опишемо як Варіант 1: (Успіх Невдача Невдача), ймовірність незалежних подій дорівнює добутку ймовірностей, тобто ймовірність того, що відмовиться саме Антон (це означає, що Богдан та Вікторія не відмовляться) дорівнює 0.35 * 0.65 * 0.65 = 0.149. Якщо відмовиться Богдан, варіант описується як Варіант 2: (Невдача Успіх Невдача), ймовірність 0.65 * 0.35 * 0.65 = 0.149. Якщо ж відмовиться Вікторія, то маємо Варіант 3: (Невдача Невдача Успіх), ймовірність якого 0.35 * 0.35 * 0.65 = 0.149. Для оцінки ймовірності, що відмовиться продовжувати одна людина, нам не важливо знати, хто саме це буде. Тобто нам треба знайти ймовірність настання Варінту 1, 2 або 3, що дорівнює сумі ймовірностей цих варіантів і дорівнює 0.44. Як бачимо, для обчислення ймовірності мати k успіхів в n незалежних випробуваннях Бернуллі з ймовірністю успіху p в кожному випробуванні використовується два компоненти: кількість можливих сценаріїв. Обчислюється за формулою: \\({n\\choose k} = \\frac{n!}{k!(n-k)!}\\) ймовірність одного сценарія Обчислюється за формулою: \\({p^k}{(1-p)^{(n-k)}}\\) В загальному формула ймовірності P мати k успіхів в n незалежних випробуваннях Бернуллі з ймовірністю успіху p в кожному випробуванні така: \\[P = {\\frac{n!}{k!(n-k)!} }{{p^k}{(1-p)^{(n-k)}}} \\] Умови: Випробування незалежні Кількість випробувань n фіксована Кожен результат класифікується як успіх або невдача Ймовірність успіху p однакова для кожного випробування Застосуємо цю формулу для прикладу: Згідно опитування Gallup poll 2012 26.2% жителів США мають надмірну вагу. Яка ймовірність серед 20 випадковим чином обраних жителів отримати 5 з надлишковою вагою? n = 20, k = 5, p = 0.262 Кількість варіантів: \\({n\\choose k} = \\frac{n!}{k!(n-k)!}\\) n! (n факторіал) - добуток всіх чисел від 1 до n (тобто 1 x 2 x 3 x … x n) \\[{n\\choose k} = \\frac{n!}{k!(n-k)!} = \\frac{20!}{5!(20-5)!} = \\frac{20!}{5!15!} = 15504 \\] Можна також використати R функцію choose: choose(n=20, k=5) ## [1] 15504 Ймовірність одного варіанту: \\[{p^k}{(1-p)^{(n-k)}} = {0.262^5}{0.738^{15}} = 0.00001295\\] Ймовірність обрати серед 20 жителів 5 з надлишковою вагою дорівнює добутку 15504 і 0.00001295 і дорівнює 0.2. Також для знаходження цього значення можемо скористатись функцією dbinom: dbinom(x=5, size=20, prob=0.262) ## [1] 0.2008148 4.5 Нормальний розподіл Нормальний розподіл є класичним неперервним розподілом. Описує розподіл багатьох неперервних величин від зросту людини до результатів виборів. Ще має назву “розподіл Гауса” (на честь Карла Фрідріха Гауса, який використовував цей розподіл для аналізу даних в астрономії). Існує нескінченна кількість нормальних розподілів в залежності від їхнього середнього значення \\(\\mu\\) та середньоквадратичного відхилення \\(\\sigma\\). джерело: wikipedia Нормальний розподіл з середнім значенням \\(\\mu = 0\\) та \\(\\sigma = 1\\) має назву стандартний нормальний розподіл або Z-розподіл. Будь-який нормальний розподіл може бути зведений до стандартного нормального розподілу шляхом Z-стандартизації. Формула для обчислення z-значень(ми розглядали її минулого тижня): \\[ z = \\frac{ x - \\mu }{\\sigma}\\] В процесі z-стандартазиції (нормалізації): Форма розподілу не змінюється Середнє значення стає нулем Середньоквадратичне відхилення стає одиницею Властивості нормального розподілу: Симетричність Юнімодальність(лише одна мода) Набирає значень від -\\(\\infty\\) до +\\(\\infty\\) Загальна площа під кривою дорівноює 1 Однакове значення медіани, моди та середнього значення. Також для нормального розподілу відомо, що близько 68% значень знаходяться в межах однього середньоквадратичиного відхилення від середнього значення близько 95% значень знаходяться в межах двох середньоквадратичиного відхилення від середнього значення близько 99% значень знаходяться в межах трьох середньоквадратичиного відхилення від середнього значення джерело: http://news.mit.edu/2012/explained-sigma-0209 Тобто, знаючи що розподіл є нормальним ми можемо визначити, наскільки типовим чи екстремальним є конкретне значення. Ми можемо також оцінити, якою є ймовірність отримати конкретне z-значення. Як оцінити ймовірність отримати конкретне z-значення? Робимо z- стандартизацію Зображаємо наш розподіл Визначаємо, який саме відрізок площі під кривою нас цікавить Знаходимо значення в z-таблицях чи з допомогою функції pnorm в R Давайте розглянемо на прикладі: виробник зимових шин декларує, що вони прослужать в середньому 51500 кілометрів та середньоквадратичне відхилення в 4000 кілометрів. Якщо ви придбаєте комплект таких шин, яка ймовірність, що вони служитимуть принаймі 63 000 кілометрів? Який відсоток цих шин прослужить менше ніж 45000? Між 45000 і 55000? Якщо ви придбаєте комплект таких шин, яка ймовірність, що вони служитимуть принаймі 63 000 кілометрів? Зобразимо наш розподіл: ggplot(data.frame(x = c(30000,70000)), aes(x)) + stat_function(fun = dnorm, colour=&quot;blue&quot;, args = list(mean = 51500, sd = 4000)) ggplot(data.frame(x = c(30000,70000)), aes(x)) + geom_vline(xintercept = 63000, linetype=2, colour=&quot;blue&quot;) + stat_function(fun = dnorm, colour=&quot;blue&quot;, args = list(mean = 51500, sd = 4000)) Принаймі 63000 - це 63000 і більше, зобразимо цю площу під кривою: ggplot(data.frame(x = c(30000,70000)), aes(x)) + geom_vline(xintercept = 63000, linetype=2, colour=&quot;blue&quot;) + stat_function(fun = dnorm, colour=&quot;blue&quot;, args = list(mean = 51500, sd = 4000)) + geom_area(stat = &quot;function&quot;, fun = dnorm, fill = &quot;red&quot;, xlim = c(63000,70000), args = list(mean = 51500, sd = 4000)) Тут у нас є два шляхи: Знайти z-значення для 63000 за формулою \\(z = \\frac{x - \\mu}{\\sigma} = \\frac{63000 - 51500}{4000} = 2.875\\) Для значення z=2.875 знайти ймовірність отримати таке ж значення або більше з допомогою z-таблиць Або скористатися функцією pnorm в R: pnorm(2.875, lower.tail = FALSE) ## [1] 0.002020137 Параметр lower.tail означає що нас цікавить ймовірність отримати значення більші, ніж 2.875. Також для функції pnorm можна не виконувати z-стандартизацію, а вказати параметри вашого розподілу: pnorm(63000, mean=51500, sd=4000, lower.tail = FALSE) ## [1] 0.002020137 Як бачимо, отримане значення становить 0.2%. Тобто ймовірність, що шини цього виробника служитимуть принаймі 63000 досить мала. Як перевірити чи розподіл є нормальним? Можна побудувати гістограму, для оцінки форми розподілу. Згенеруємо 1000 випадкових чисел, які мають нормальний розподіл. Для цього скористаємося функцією rnorm (по замовчуванню \\(\\mu = 0\\), \\(\\sigma = 1\\)) x &lt;- rnorm(1000) Побудуємо гістограму: ggplot(data.frame(x), aes(x)) + geom_histogram(bins=20, color=&quot;grey&quot;, fill=&quot;lightblue&quot;) Ще для оцінки форми розподілу можна використовувати так званий density plot (відображає густину ймовірності): ggplot(data.frame(x), aes(x)) + geom_density(color = &quot;blue&quot;) Ще одна з технік візуального аналізу - quantile-quantile plot(qqplot). Минулого тижня ми з вами розглядали квартилі, які ділять дані на чотири частини. Ще є децилі - ділять дані на десять частин (перший дециль відокремлює 10% найменших величин, другий 20% і т д) та персентилі, де дані поділені на сто частин (25 персентиль співпадає з першим квартилем, 50 з медіаною, 75 з третім квартилем). qqnorm(x) qqline(x, col=&#39;red&#39;) Для бібліотеки ggplot2 y1 &lt;- quantile(x, c(0.25, 0.75)) # Find the 1st and 3rd quartiles x1 &lt;- qnorm(c(0.25, 0.75)) # Find the matching normal values on the x-axis slope &lt;- diff(y1) / diff(x1) # Compute the line slope int &lt;- y1[1] - slope * x1[1] # Compute the line intercept ggplot(data.frame(x), aes(sample = x)) + stat_qq() + geom_abline(intercept=int, slope=slope, col=&quot;red&quot;) Якщо точки вашого розподілу розташовані по прямій, яка позначена червоним кольором, можна стверджувати що ваш розподіл співпадає з теоретичним нормальним розподілом. Ще одна корисна властивість: біноміальний розподіл, де очікується принаймі 15 успіхів та 15 невдач, поводить себе як нормальний розподіл, де \\(\\mu = np\\), \\(\\sigma = \\sqrt{np(1-p)}\\) Binomial (n, p) ~ Normal(\\(\\mu, \\sigma\\)) np ≥ 15 n(1-p) ≥ 15 4.6 Коваріація та кореляція До цього часу ми працювали над аналізом однієї змінної. Тепер ми перейдемо до аналізу взаємозв’язків між двома змінними. Коваріація – міра лінійної залежності двох випадкових величин одна від одної. Кореляція – зважена версія коваріації. Коефіцієнт кореляції (ще має назву коефіцієнт Пірсона) обчислюється за формулою: \\[r = \\frac{cov(X,Y)}{\\sqrt{var(X)} \\sqrt{var(Y)}} = \\frac {\\sum{(x_i - \\bar{x})(y_i - \\bar{y})}}{\\sqrt{\\sum{(x_i - \\bar{x})^2}\\sum{(y_i - \\bar{y})^2}}}\\] В R коефіцієнт для обчислення коефіцієнта кореляції використовується функція cor, яка по замовчуванню рахує коефіцієнт кореляції Пірсона(є й інші коефіцієнти кореляції). Абсолютне значення коефіцієнта кореляції дає уявлення про силу лінійного зв’язку між двома змінними. Знак коефіцієнта вказує напрямок зв’язку. Коефіцієнт кореляції набуває значень [– 1,1]. Якщо коефіцієнт близький до 1 - говорять про сильну позитивну кореляцію, до -1 про сильну негативну. Значення коефіцієнта близькі до 0 вказують на відсутність лінійної кореляції. Властивості коефіцієнта кореляції: коефіцієнт кореляції не змінюється при зміні одиниць виміру(наприклад від кілограм до грам) коефіцієнт кореляції є симетричним r(x, y) = r(y, x) коефіцієнт кореляції чутливий до викидів 4.7 Лінійна регресія Якщо коефіцієнт кореляції дає нам розуміння чи є лінійна залежність між двома змінними, то лінійна регресія дає модель для оцінки як зміниться одна змінна при зміні іншої. Наприклад, може визначити, як вага дорослої анаконди при зміні її довжини. anaconda &lt;- read.csv(&quot;anaconda.dat&quot;, sep=&quot;&quot;, header = FALSE) colnames(anaconda) &lt;- c(&quot;Height&quot;, &quot;Weight&quot;, &quot;Sex&quot;) Побудуємо графік розсіювання для наших даних: ggplot(anaconda, aes(x=Height, y=Weight)) + geom_point(col=&quot;blue&quot;) На основі цього графіка, можемо припустити, що є позитивна лінійна залежність між довжиною та вагою дорослих анаконд. Знайдемо коефіцієнт кореляції: cor(anaconda$Height, anaconda$Weight) ## [1] 0.9613875 Дійсно, ці дві змінні мають сильну позитивну лінійну залежність. Лінійна регресія передбачає що ми побудуємо лінію, яка якнайкраще описуватиме наші дані. Формула цієї лінії: \\[\\hat y = ax + b\\] де x - незалежна змінна (в нашому прикладі це довжина), y - залежна змінна (вага анаконд). a - це кут нахилу цієї прямої (slope) b - точка перетину з y, де x = 0 (intercept) Як знайти цб лінію? Через ці точки можна провести безліч ліній, один з найчастіше вживаних для побудови “найкращої лінії” - метод найменших квадратів. Серед всіх ліній, найкращою ввжається та, сума квадратів залишків якої є найменшою. Залишок - ці різниця між справжнім значенням залежної змінної y та тим, яке передбачає моделі, тобто \\(y - \\hat y\\). Відповідно в процесі знаходження найкращої ліній ми мінімізуємо \\(\\sum{(y - \\hat y)^2}\\). Є формули для обчислення коефіцієнтів a та b. Однак ми скиристаємось функціоналом R. Для знаходження найкращої лінії, яка й буде нашою моделлю, будемо використовувати функцію lm. Вказуємо формулу залежності Weight ~ Height означає, шо ми будуємо лінійну модель залежності змінної Weight від змінної Height. prediction_model &lt;- lm(Weight ~ Height, data=anaconda) Для оцінки результатів лінійної моделі використовується функція summary: summary(prediction_model) ## ## Call: ## lm(formula = Weight ~ Height, data = anaconda) ## ## Residuals: ## Min 1Q Median 3Q Max ## -9.2050 -3.9127 -0.2454 1.9430 16.8067 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) -50.730584 2.946034 -17.22 &lt;2e-16 *** ## Height 0.253047 0.009857 25.67 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 5.754 on 54 degrees of freedom ## Multiple R-squared: 0.9243, Adjusted R-squared: 0.9229 ## F-statistic: 659 on 1 and 54 DF, p-value: &lt; 2.2e-16 Давайте подивимось, яку інформацію про модель ми отримали: Значення коефіцієнта Height(відповідає a в загальній моделі \\(\\hat y = ax +b\\)) становить 0.253, Intercept(відповідаєb) становить -50.73. Тобто формула залежності ваги анаконди від її довжини: \\[\\hat Weight = 0.253 Height -50.73 \\] Це означає, що при збільшенні довжини на 1 см, вага збільшується на 0.253 кг або ж 253 грами. Також досить корисним для трактування результатів є коефіцієнт \\(R^2\\). Рахується як квадрат коефіцієнта кореляції, тому має значення від 0 до 1. Основна його цінність у тому, що він говорить, який відсоток варіативності залежної змінної пояснюється лінійною моделлю. Відповідно залишок пояснюється змінними, які не включені в модель. Для лінійної моделі залежності ваги анаконд від їх довжини залишок складає 8%. До змінних, які можуть покращити модель належить, наприклад, стать або вік цих анаконд. Також в ggplot2 (як і в базовому функціоналі R) лінію регресії можна додати до графіка розсіювання: ggplot(anaconda, aes(x=Height, y=Weight)) + geom_point(col=&quot;blue&quot;) + geom_smooth(method = &quot;lm&quot;, se=FALSE) Умови для побудови лінійної регресії: Лінійність (тобто наявність лінійної залежності між незалежною та залежною змінною) Нормальний розподіл залишків Гомоскедастичність (стала варіативність залишків) За цим посиланням https://gallery.shinyapps.io/slr_diag/ ви можете змоделювати дані з різними типами залежності та дослідити, як при цьому будуть виглядати лінія регресії, коефіцієнт кореляції, \\(R^2\\), та як виглядає розподіл залишків. Екстраполяція – застосування моделі, до діапазону даних., для якого моделювання не проводилося. Сам підхід гарно ілюстрює XKCD комікс http://xkcd.com/605/. Якщо ви сьогодні вийшли заміж, то вчора у вас було 0 чоловіків, сьогодні 1, через місяць 30, а через рік 365 :) Важливо уникати екстраполяції, оскільки ми не знаємо, як зміниться тренд для даних, яких ми ще не бачили. "],
["inferentialstats.html", "Розділ 5 Вивідна статистика 5.1 Центральна гранична теорема 5.2 Довірчий інтервал 5.3 Розмір вибірки 5.4 Довірчий інтервал для середнього значення 5.5 Покроковий план побудови довірчого інтервалу", " Розділ 5 Вивідна статистика Описова статистика – вивчає властивості спостережуваних даних. Вивідна статистика – виводимо припущення про властивості розподілу даних з яких походять спостережувані дані. Описова статистика цікавиться виключно властивостями спостережуваних даних, і не припускає, що ці дані можуть походити з більшої сукупності.Вивідна статистика дозволяє робити висновки про генеральну сукупність на основі вибірки. Впевненість у цих висновках можна представити чисельно. Розуміння термінів “генеральна сукупність” та “вибірка” є надзвичайно важливим для розуміння вивідної статистики. “Генеральна сукупність” складається з усіх об’єктів (наприклад людей, лососів в Атлантичному океані, деталей літака) предмету, які хотів би вивчити дослідник, якби в нього була необмежена кількість ресурсів. Визначення генеральної сукупності, яка досліджується є першим кроком у вивідній статистиці. Прикладом генеральної сукупності може бути населення США у 2016 році або кількість канадських чоловіків віком 65-70 років з діагнозом серцева недостатність. Статистичний процес для вивідної та описової статистик однаковий, але трактування різне. Наприклад, середнє значення обчислюється однаково як для популяції так і для вибірки. Для їх розрізнення використовується інша нотація. Ви можете зауважити, що формули для обчислення дисперсії(а отже і середньоквадратичного відхилення) для генеральної сукупності та вибірки відрізняються. Наш курс є вступним і не передбачає заглиблення в це питання, однак ви можете детальніше прочитати, чому ми робимо цю корекцію (вона ще має назву корекція або ж поправка Бесселя) за посиланням: https://en.wikipedia.org/wiki/Bessel%27s_correction Практично всі дослідження базуються на даних, отриманих з вибірок, а не на даних генеральної сукупності з практичних міркувань(обмеження часу та ресурсів). Винятками є дослідження на кшталт U.S.Census(https://en.wikipedia.org/wiki/United_States_Census_Bureau), головна мета яких охопити всіх жителів США у визначеному році. Репрезентативна вибірка -представляє генеральну сукупність, можна використовувати для вивідної статистики.Нерепрезентативна вибірка: вибірка та генеральну сукупність мають різні характеристики. Використання цієї вибірки призведе до неправильних результатів аналізу. Розрізняють ймовірнісні вибірки та вибірки сформовані згідно певних правил. При використанні останніх є високий ризик отримати нерепрезентативну вибірку. Прикладом є “волонтерська вибірка” - коли опитують лише бажаючих взяти участь в дослідженні чи “зручна вибірка” (сonvinience sampling), яка формується з доступних для дослідження об’єктів. Опитування слухачів на форумі цього курсу про їх політичні уподобання (якщо в якості генеральної сукупності виступає все доросле населення України) буде водночас і волонтерською, і зручною вибіркою. Якщо вам потрібно сформувати репрезентативну вибірку - то ймовірнісні вибірки є найкращим вибором. Найпоширенішим видом ймовірнісної вибірки є простий випадковий вибір (simple random sampling). Всі об’єкти генеральної сукупності мають однакову можливість бути вибраними. Також виділяють: стратометричний вибір - сукупність ділиться на страти (наприклад, населення за рівнем освіти чи віковою групою) кластерний вибір - сукупність ділиться на кластери, які однакові за своєю структурою, потім випадковим чином обираються кластери, а тоді елементи цих кластерів cистематичний вибір - елементи сукупності впорядковуються і вибирається кожен k-ий елемент (елементи на конвейері з метою виявлення дефектів) 5.1 Центральна гранична теорема Нехай ми досліджуємо зріст дорослих чоловіків, які проживають на території Європи. В нашому дослідженні вони представляють генеральну сукупність з параметрами \\(\\mu\\) та \\(\\sigma\\). Ми можемо сформувати вибірки для оцінки середнього значення зросту дорослого чоловіка. Наприклад, визначити середнє значення зросту дорослого чоловіка та середньоквадратичне відхилення для кожної країни Європи. Чи сформувати 1000 вибірок, випадковим чином обравши 40 чоловіків для кожної. Середнє значення кожної вибірки буде точковою оцінкою для середнього значення генеральної сукупності. Тут маємо три розподіли: розподіл генеральної сукупності (середнє значення \\(\\mu\\), середньоквадратичне відхилення \\(\\sigma\\), переважно невідомий) розподіл вибірки (середнє значення x, середньоквадратчине відхилення s, використовується для оцінки параметрів генеральної сукупності) вибірковий розподіл - розподіл середніх значень вибірок. Центральна гранична теорема: Незалежно від того, який розподіл має змінна у популяції (генеральній сукупності), вибірковий розподіл середніх значень вибірок має приблизно нормальний розподіл, якщо розмір вибірки принаймі 30.Середнє значення вибіокового розподілу \\(\\mu_x\\) дорівнює середньому значенню генеральної сукупності \\(\\mu\\), а середньоквадратичне відхилення буде обчислюватись за формулою \\(s = \\frac{\\sigma}{\\sqrt{n}}\\), де \\(\\sigma\\) - середньоквадратичне відхилення генеральної сукупності, а n - розмір вибірки. Вибірковий розподіл пропорцій вибірок має приблизно нормальний розподіл за умови наявності принаймі 15 успіхів та 15 невдач, тобто np ≥ 15 та n(1-p) ≥ 15. При цьому середнє значення пропорцій вибірок \\(\\mu_p\\) дорівнює значенню пропорції генеральної сукупності p, а середньоквадратичне відхилення \\(s(\\bar p) =\\sqrt{\\frac{p(1 - p)}{n}}\\). Знання, що розподіл є нормальним, дозволяє оцінити ймовірність на основі Z-значень. Тобто, використовуючи центральну граничну теорему ми можемо оцінити ймовірність отримати вибірку з певним середнім значенням чи значенням пропорції. Розглянемо приклади застосування центральної граничної теореми. Ви збираєтесь на пробіжку, яка триватиме 2 години. Ви створили плейлист, з випадковим чином обраних 40 пісень. Яка ймовірність що цей плейлист не закінчиться протягом пробіжки? Середня довжина пісні становить 3.45 хв, середньоквадратичне відхилення – 1.63 хв). Тривалість пробіжки в хвилинах становить 120 хвилин. Нам потрібно оцінити ймовірність, що сума тривалостей 40 пісень буде довшою ніж P(x1 + x2 + … + x40) &gt; 120 P(\\(\\bar x\\) &gt; 3) ? Середньоквадратичне відхилення вибіркового розподілу(розподілу середніх значень вибірок) згідно центральної граничної теореми обчислюється за формулою: \\(s= \\frac{\\sigma}{\\sqrt{n}} = \\frac{1.63}{\\sqrt{40}} = 0.258\\) Знайдемо z-значення: \\[z = \\frac{x - \\mu}{s} = \\frac{3 - 3.45}{0.258} = -1.74\\] Зобразимо розподіл та площу під кривою: library(ggplot2) ggplot(data.frame(x = c(-3,3)), aes(x)) + geom_vline(xintercept = -1.74, linetype=2, colour=&quot;blue&quot;) + stat_function(fun = dnorm, colour=&quot;blue&quot;) + geom_area(stat = &quot;function&quot;, fun = dnorm, fill = &quot;red&quot;, xlim = c(-1.74,3)) Знайдемо ймовірність отримати z-значення -1.74 або більше: pnorm(-1.74, lower.tail = FALSE) ## [1] 0.9590705 Отже, ймовірність того, що плейліст не закінчиться становить 95.9% Розглянемо інший приклад. Припустимо, що частка всіх студентів університету, які вживали енергетики протягом останніх 6 місяців становить р = 0.40. Для вибірки n = 200 студентів, яка ймовірність, що відсоток тих, хто вживав енергетики протягом останніх 6 місяців менша ніж 32%? n = 200 p = 0.40 P(\\(\\bar p\\) &lt; 0.32) - ? Перевіримо умови, які потрібні для застосування центральної граничної теореми: np = 200 \\(\\times\\) 0.40 = 80 ≥ 15 n(1-p) = 200 \\(\\times\\) (1 - 0.40) = 120 ≥ 15 Умови виконуються. Обчислимо середньоквадратичне відхилення вибіркового розподілу: \\(s(\\bar p) =\\sqrt{\\frac{p(1 - p)}{n}} = \\sqrt{\\frac{p(1-p)}{n}}= \\sqrt{\\frac{0.4(1-0.4)}{200}} =0.0346\\) z-значення: \\(\\frac{0.32 - 0.40}{0.0346} = -2.31\\) Зобразимо розподіл та площу під кривою: ggplot(data.frame(x = c(-3,3)), aes(x)) + geom_vline(xintercept = -2.31, linetype=2, colour=&quot;blue&quot;) + stat_function(fun = dnorm, colour=&quot;blue&quot;) + geom_area(stat = &quot;function&quot;, fun = dnorm, fill = &quot;red&quot;, xlim = c(-3,-2.31)) Знайдемо ймовірність отримати z-значення -2.31 або більше: pnorm(-2.31) ## [1] 0.01044408 Ймовірність, що у вибірці з 200 випадковим чином обраних студентів відсоток тих, хто вживав енергетики протягом останніх 6 місяців буде менша ніж 32% становить 1%. 5.2 Довірчий інтервал Точкова оцінка це одне число, яке є нашою найкращою здогадкою про значення параметрів популяції. Однак, одна точкова оцінка не говорить, наскільки близькою ця оцінка є до справжньої пропорції генеральної сукупності. Тобто наступним кроком має бути оцінка точності цієї точкової оцінки. Інший тип – інтервальна оцінка (довірчий інтервал, confidence interval, CI). Це інтервал значень, який з високою ймовірністю містить справжні параметри генеральної сукупності. Ймовірність що цей інтервал містить середнє значення чи значення пропорції генеральної сукупності визначається рівнем довіри. Рівень довіри(рівень надійності, confidence level) має значення близьке до одиниці(найбільш поширені значення 90%, 95%, 99%). Загальна формула: точкова оцінка(estimate) \\(\\pm\\) межа похибки(margin of error) точкова оцінка(estimate) \\(\\pm\\) критичне значення \\(\\times\\)середньоквадратичне відхилення точкової оцінки Точкова оцінка - значення середнього чи пропорції для вибірки Критичне значення - це значення для \\(\\frac{1-\\alpha}{2}\\), де \\(\\alpha\\) - рівень довіри. Наприклад, для рівня довіри \\(\\alpha = 95\\%\\) критичне значення z розподілу становить 1.96(тобто 95% лежать в межах \\(\\pm 1.96\\)) середньоквадратчиних відхилень. Чому ми можемо використати властивості нормального розподілу для побудови довірчого інтервалу? Це нам дозволяє робити центральна гранична теорема, яка говорить, що неважливо який розподіл даних у генеральній сукупності, вибірковий розподіл(тобто розподіл середніх значень вибірок) буде мати нормальний розподіл. Давайте розглянемо приклад: Нехай серед 935 випадковим чином обраних респондентів на питання “чи виріте ви в існування розумного життя на інших планетах?” ствердно відповіли 60%. Тобто \\(\\bar p = 0.6\\), n=935. \\(\\bar p = 0.6\\) - точкова оцінка. Побудуємо інтервальну оцінку, тобто довірчий інтервал для оцінки пропорції тих, хто вірить в життя на інших планетах. Рівень довіри \\(\\alpha = 95\\%\\). Центральна гранична теорема говорить, що при виконанні умов np ≥ 15 та n(1-p) ≥ 15 розподіл пропорцій вибірок буде нормальним, де значення p(пропорція генеральної сукупності) ~ \\(\\bar p\\), а середньоквадратичне відхилення обчислюється за формулою \\(s(\\bar p) = \\sqrt{\\frac{p(1 - p)}{n}}\\). Перевіримо умови: np = 935 \\(\\times\\) 0.6 = 561$ ≥ 15 n(1-p) = 935 \\(\\times\\) (1 - 0.6) = 374 ≥ 15 Умови виконуються, тому можемо використовувати центральну граничну теорему для обрахування довірчого інтервалу оцінки для значення пропорції генеральної сукупності. Середнє значення вибіркового розподілу дорівнює значенню \\(\\bar p\\) = 0.6. Середньоквадратичне відхилення цього розподілу обчислюється за формулою \\(s(\\bar p) = \\sqrt{\\frac{p(1 - p)}{n}} = \\sqrt{\\frac{0.6 \\times (1-0.6)}{935}} = 0.016\\) Критичне значення для рівня довіри \\(\\alpha = 95\\%\\) становить 1.96. Підставимо отримані значення в формулу, точкова оцінка(estimate) \\(\\pm\\) межа похибки(margin of error), де межа похибки дорівнює критичне значення \\(\\times\\)середньоквадратичне відхилення точкової оцінки. Отримаємо: Довірчий інтервал з рівнем довіри 95% (CI 95%) : 0.6 \\(\\pm\\) 1.96 \\(\\times\\) 0.016. Або 0.6 \\(\\pm\\) 0.03136 чи [0.56864, 0.63136] Тобто ми можемо стверджувати(з впевненістю 95%), що відсоток людей, які вірять в існування життя на інших планетах, згідно нашого дослідження знаходиться в межах [56.864%, 63.136%]. Рівень довіри в 95% для довірчого інтервалу говорить що в ми на 95% можемо бути впевнені, що наша справжнє значення генеральної сукупнсті потрапляє в цей інтервал. Тобто якщо цих інтервалів багато – 95% містять справжнє значення параметра. Це також означає, що його 5% не містять. Якщо ви хочете зменшити кількість таких випадків – можна збільшити рівень довіри, наприклад до 99%. Однак, довірчий інтервал при цьому буде ширший. Побудуємо довірчі інтервали з рівнем довіри 90%, 95% та 99% для нашого опитування про існування розумного життя на інших планетах. Формула для обрахунку \\(p \\pm Z_{90\\%} + se(\\bar p)\\): Для рівня довіри 90% z-значення становитиме 1.64. Решту даних ми маємо. Тоді 90% CI: \\(0.6 \\pm 1.64 \\times 0.016\\) = [0.57376, 0.62624]. Аналогічно для рівня довіри 95%: 95% CI: \\(p \\pm Z_{95\\%} + se(\\bar p) = 0.6 \\pm 1.96 \\times 0.016\\) = [0.56864, 0.63136] Та для рівня довіри 99%: 99% CI: \\(p \\pm Z_{99\\%} + se(\\bar p) = 0.6 \\pm 2.58 \\times 0.016\\) = [0.55872, 0.64128] Бачимо, що що із збільшенням рівня довіри, ширина довірчого інтервалу збільшується, тобто чим більшою є наша впевненість, що значення параметра потрапляє до інтервалу, тим ширшим є цей інтервал. 5.3 Розмір вибірки Давайте поглянемо на формули для визначення середньоквадратичного відхилення вибіркового розподілу: \\(s = \\frac{\\sigma}{\\sqrt n}\\) - для середнього значення \\(s = \\sqrt{\\frac{p(1 - p)}{n}}\\) - для пропорції В обох формулах у знаменнику маємо n - розмір вибірки. Відповідно, при збільшенні n, значення середньоквадратичного відхилення(а отже і межі похибки) будуть зменшуватись. Тобто, ми можемо визначити таке n при якому межа похибки набуває визначеного значення. Розглянемо це на прикладі. Нехай дослідження показало, що 43% дорослих віком від 25 до 35 років співає в душі. Дослідник хоче визначити, чи це справедливо для дорослих віком від 35 років. Яким має бути розмір вибірки, щоб мати межу похибки рівну 5% для рівня довіри 90%? Для того, щоб перевірити, чи справедливе твердження що 43% дорослих співає в душі для вікової групи ≥ 35 років, спочатку знайдемо межі похибки довірчого інтервалу для вікової групи 25-35 років. Рівень довіри \\(\\alpha = 90\\%\\), критичне значення \\(Z_{90\\%} = 1.64\\) \\(\\bar p = 0.43\\) Межа похибки: критичне значення \\(\\times\\)середньоквадратичне відхилення точкової оцінки (згідно умови становить 5%) тобто маємо рівняння: \\[0.05 = 1.64 \\times \\sqrt{\\frac{p(1 - p)}{n}} = 1.64485 \\times \\sqrt{\\frac{0.43(1 - 0.43)}{n}}\\] Визначимо з цього рівняння n: \\[0.05 \\sqrt n = 1.64485 \\times \\sqrt{0.43 \\times 0.57}\\] \\[\\sqrt n = 1.64485 \\times \\frac{\\sqrt{0.43 \\times 0.57}}{0.05}\\] \\[\\sqrt n = 16.28651\\] \\[n = 16.28651 ^2 = 265.25\\] Тобто, щоб отримати межу похибки 5% (або меншу), потрібно опитати принаймі 266 людей. 5.4 Довірчий інтервал для середнього значення Давайте розглянемо процес побудови довірчого інтервалу для оцінки середнього значення генеральної сукуаності на основі даних вибірки. Для визначення екваторіального радіусу планети Марс провели 40 незалежних вимірювань. Ці вимірювання мають середнє значення \\(\\bar x\\) = 3396 км та середньоквадратичне відхилення s = 30 км. Знайдіть 95% довірчий інтервал для екваторіального радіуса планети Марс. n = 40 \\(\\bar x\\) = 3396 s = 30 Центральна гранична теорема говорить, що при n &gt; 30 вибірковий розподіл, тобто розподіл середніх значень є нормальним. Середнє значення цього розподілу \\(\\mu_x = \\mu\\), а середньоквадратичне відхилення \\(s = \\frac{\\sigma}{\\sqrt{n}}\\), де \\(\\mu\\) та \\(\\sigma\\) - середнє значення та середньоквадратичне відхилення генеральної сукупності. Для побудови довірчого інтервалу використаємо формулу: точкова оцінка(estimate) \\(\\pm\\) межа похибки(margin of error) точкова оцінка(estimate) \\(\\pm\\) критичне значення \\(\\times\\)середньоквадратичне відхилення точкової оцінки Для середнього значення з рівнем довіри 95% вона буде виглядати так: \\(\\bar x \\pm Z_{95\\%} \\times \\frac{\\sigma}{\\sqrt n}\\) Якщо у нас відоме значення середньоквадратичного відхилення \\(\\sigma\\), то можемо використовувати цю формулу. Однак, в реальному житті(як і в прикладі оцінки радуісу Марса), нам зазвичай невідоме значення \\(\\sigma\\). Що робити в цій ситуації? Для оцінки середньоквадратичного відхилення вибіркового розподілу використовують середньквадратичне значення вибірки s, однак в якості теоретичного розподілу середніх значень використовують t-розподіл(розподіл Стьюдента). Є велика кількість t-розподілів, в залежності від кількості ступенів вільності(degrees of freedom) форма цих розподілів відрізняється(а отже і площа під кривою, і ймовірності мати значення більше чи менше заданого). Що таке ступені вільності? Розглянемо це на прикладі однієї змінної. Нехай у нас є 9 клітинок та 9 чисел. Якщо для перших 8 є можливість вибору, в яку клітинку їх розмістити, то останнє число буде в останній клітинці, що залишиться(без можливості вибору). Тобто тут кількість ступенів вільності становить n - 1 Для побудови довірчих інтервалів будемо використовувати цю формулу. Тобто кількість ступенів вільності для нашої вибірки з вимірами радуісу Марса дорівнює n - 1 = 40 - 1 = 39. Формула для побудови довірчого інтервалу наступна: \\[\\bar x \\pm t_{95\\%} \\times \\frac{s}{\\sqrt n}\\] де \\(t_{95\\%}\\) - критичне значення t-розподілу з кількістю ступенів вільності n-1(в нашому прикладі 39) для рівня довіри \\(\\alpha = 95\\%\\) Критичне значення t-статистики залежить від кількості ступенів вільності. Можна користуватисть t-таблицями, але в межах цього курсу ми будемо використовувати функціонал R. Для визначення критичного значення використовується функція qt з параметрами \\(\\frac{1-\\alpha}{2}\\) та кількістю ступенів вільності df. Для нашого прикладу критичне значення рахується так: n = 40 alpha = 0.95 qt((1-alpha)/2, df=n-1, lower.tail = FALSE) ## [1] 2.022691 Тоді межа похибки(margin of error) обчислюється за формулою \\(t_{95\\%} \\times \\frac{s}{\\sqrt n} = 2.02 \\times \\frac{30}{\\sqrt{40}} = 9.58\\) Відповідно довірчий інтервал: 3396 ± 9.58 або [3386.42, 3405.58]. 5.5 Покроковий план побудови довірчого інтервалу Визначити рівень довіри (поширені значення 90%, 95%, 99%) Визначити середнє значення чи пропорція. Для пропорції: знаходимо критичне значення z-розподілу для заданого рівня довіри знаходимо межу похибки(margin of error): \\(Z_{\\alpha} \\times \\sqrt{\\frac{p(1 - p)}{n}}\\) Для середнього значення: Якщо відоме значення середньоквадратичного відхилення генеральної сукупності: знаходимо критичне значення z-розподілу для заданого рівня довіри знаходимо межу похибки(margin of error): \\(Z_{\\alpha} \\times \\frac{\\sigma}{\\sqrt{n}}\\) Якщо значення середньоквадратичного відхилення генеральної сукупності невідоме: знаходимо кількість ступенів вільності за формулою n-1, де n - розмір вибірки знаходимо критичне значення t-розподілу відповідно до кількості ступенів вільності знаходимо межу похибки(margin of error): \\(t_{\\alpha} \\times \\frac{\\sigma}{\\sqrt{n}}\\) Визначаємо межі інтервалу за формулою точкова оцінка(estimate) \\(\\pm\\) межа похибки(margin of error) Інтерпретація результату "],
["hypothesistest.html", "Розділ 6 Тестування гіпотез", " Розділ 6 Тестування гіпотез Коли дослідники мають очікування щодо параметрів генеральної сукупності – говорять про статистичну гіпотезу. Зазвичай, гіпотеза формулюється як твердження що параметр генеральної сукупності має певне значення або знаходиться в певному інтервалі. Це твердження базується на попередніх дослідженнях та теорії. На основі інформації, отриманої з вибірки оцінюють, чи має сенс (справедливе) це твердження чи ні. Це те, що ми називаємо тест на значущість. Тест на значущість, як і побудова довірчих інтервалів, є методом вивідної статистики. Ми пробуємо оцінити параметри генеральної сукупності на основі вибірки. Тест на значущість базується на двох гіпотезах: це нульова та альтернативна гіпотези. Нульова гіпотеза позначається як H0, альтернативна як На. Нульова гіпотеза стверджує, що параметр генеральної сукупності набирає конекретного значення. Ця гіпотеза може бути відхилена, якщо дані вибірки кажуть що це дуже нетипові очікування. Альтернативна гіпотеза стверджує, що параметр, який досліджується має альтернативне значення чи набір значень. Нульова та альтернативна гіпотези завжди взаємовиключні (mutually exclusive). Коли ви робите тест на значимість, ви вважаєте, що нульова гіпотеза правдива поки дані вибірки не дадуть достатньо сильні аргументи, що це не так. Це схоже на суд присяжних. Прокурор пробує переконати суддів, що підсудний винен. Підсудний не має доводити свою невинність і вважається невинним, поки прокурор не доведе інакше. Як формулюються гіпотези? Нехай дослідження показало, що пульс студентів університету становить 70 ударів за хвилину: Стандартне значення становить 72 удари. Дослідник хоче визначити чи відрізняються результати вибірки від загальних результатів \\(H_A: \\mu \\neq 72\\) \\(H_0: \\mu = 72\\) Тестування гіпотез для середнього значення 9 листопада 1965 року в енергосистемі США сталася аварія. 30 мільйонів людей протягом 13 годин перебували без світла. Через 9 місяців (10 серпня 1966) в NY Times опубліковане дослідження, яке стверджувало що значно зросла народжуваність table will be here witrh parameteres Ми хочемо дізнатись, чи відрізняється це значення від звичайного рівня народжуваності в Нью Йорку (середня кількість новонароджених 430 на добу) Нульова гіпотеза: Відключення електроенергії у листопаді 1965 року впливу на кількість новонароджених не має, тобто таке ж саме як і в інші місяці. \\(H_0 = 430\\) (звична кількість новонароджених) Альтернативна гіпотеза: Відключення електроенергії у листопаді 1965 має вплив на кількість новонароджених \\(H_A \\neq 430\\) Це двостороння альтернатива, що означає що рівень народжуваності відрізняється. Можемо також розглядати односторонню альтернативу, наприклад \\(H_A &gt; 430\\) Тестова статистика вимірює різницю між даними отриманої вибірки та нульовою гіпотезою. Фактично тестова статистика відповідає на питання: ”Яка відстань у середньоквадратичних відхиленнях між середнім значенням отриманої вибірки та середнім значенням згідно нульової гіпотези” Для рівня народжуваності в Нью Йорку середнє значення вибірки становить 432.21, а середнє значення згідно нульової гіпотези 430. Щоб обрахувати тестову статистику нам потрібно знати середньоквадратичне відхилення для вибірки. тестова статистика для середнього значення вибірки Середнє значення вибірки має середньоквадратичне відхилення \\(\\frac{\\sigma}{\\sqrt{n}}\\), наша тестова статистика буде обчислюватись за формулою: \\[ Z = \\frac{\\bar X - \\mu_0}{\\frac{\\sigma}{\\sqrt{n}}}\\] Z – кількість середньоквадратичних відхилень між середнім значенням вибірки та середнього значення згідно нульової гіпотези Для обрахування тестової статистика Z потрібно знати середьноквадратичне відхилення генеральної сукупності \\(\\sigma\\) Ми вже знаємо, що в цьому випадку можна використовувати t-розподіл. Тобто потрібно обрахувати \\[ t = \\frac{\\bar X - \\mu_0}{\\frac{s}{\\sqrt{n}}}\\] Для нашого прикладу середнє значення вибірки 432.21, середнє значення згідно нульової гіпотези середнє значення 430, середньоквадратичне відхилення вибірки 40.48. Розмір вибірки: 14. Тестова статистика: \\[ t = \\frac{\\bar X - \\mu_0}{\\frac{s}{\\sqrt{n}}} = \\frac{432.21 - 430}{\\frac{40.48}{\\sqrt{14}}} = 0.204\\] Тобто, середнє значення отриманої вибірки знаходиться на відстані 0.204 середньоквадратичних відхилень від середньоквадратичного значення нульової гіпотези. Чи ця різниця є статистично значимою? Чи можливо ми отримали це значення випадково? значення ймовірності (p-value) За припущення, що нульова гіпотеза правдива, p-value відповідає на питання “яка ймовірність отримати значення більш екстремальне ніж наще спостережуване середнє значення” Чим менше p-value тим більш нереалістичною є нульова гіпотеза Для нашого прикладу t =0.204. За припущення що середнє значення нашої генеральної сукупності 430, яка ймовірність отримати вибірку, з t статистикою 0.204 або більш екстремальне? library(ggplot2) ggplot(data.frame(x = c(-3,3)), aes(x)) + geom_vline(xintercept = 0.204, linetype=2, colour=&quot;blue&quot;) + geom_vline(xintercept = -0.204, linetype=2, colour=&quot;blue&quot;) + stat_function(fun = dnorm, colour=&quot;blue&quot;) + geom_area(stat = &quot;function&quot;, fun = dnorm, fill = &quot;lightblue&quot;, xlim = c(0.204, 3)) + geom_area(stat = &quot;function&quot;, fun = dnorm, fill = &quot;lightblue&quot;, xlim = c(-3, -0.204)) p.val &lt;- 2*pt(0.204, df=13, lower.tail = FALSE) p.val = 0.841 статистична значущість Ми порівнюємо отримане p-value з фіксованим значенням, яке є вирішальним наскільки ми маємо доказів, щоб відкинути нульову гіпотезу. Це вирішальне значення має назву рівень значущості та позначаєтся \\(\\alpha\\) Загально прийнятим \\(\\alpha\\) рівнем є \\(\\alpha =0.05\\). Це означає, що докази які ми отримали проти нульової гіпотези настільки сильні, що можуть бути отримані в результаті випадкового збігу не більше ніж в 5% (якщо нульова гіпотеза справедлива). Якщо p-value менше ніж \\(\\alpha\\) говорять, що різниця статистично значима для рівня \\(\\alpha\\) Для обчислення значення p-value будемо використовувати той факт t-розподіл \\[ t = \\frac{\\bar X - \\mu_0}{\\frac{s}{\\sqrt{n}}} = \\frac{432.21 - 430}{\\frac{40.48}{\\sqrt{14}}} = 0.204\\] \\(H_0: \\mu = 430\\) \\(H_A: \\mu \\neq 430\\) \\(\\alpha = 0.05\\) df = n - 1 = 13 Критичний регіон x_vector &lt;- c(452, 470, 431, 448, 467, 377, 344, 449, 440, 457, 471, 463, 405, 377) n = 14 alpha = 0.05 qt(1 - alpha/2, df = n - 1) ## [1] 2.160369 # 2.160369 t.test(x_vector, alternative = &quot;two.sided&quot;, mu=430, conf.level = 0.95) ## ## One Sample t-test ## ## data: x_vector ## t = 0.20464, df = 13, p-value = 0.841 ## alternative hypothesis: true mean is not equal to 430 ## 95 percent confidence interval: ## 408.8384 455.5901 ## sample estimates: ## mean of x ## 432.2143 t.test(x_vector, alternative = &quot;greater&quot;, mu=430, conf.level = 0.95) ## ## One Sample t-test ## ## data: x_vector ## t = 0.20464, df = 13, p-value = 0.4205 ## alternative hypothesis: true mean is greater than 430 ## 95 percent confidence interval: ## 413.0523 Inf ## sample estimates: ## mean of x ## 432.2143 # x_vectort = 0.20464, df = 13, p-value = 0.4205 p_value = 0.841 &gt; \\(/alpha\\) трактування результатів Для кількості новонароджених у Нью Йорку p-значення = 0.814, що не дозволяє відкинути нульову гіпотезу для рівня значущості \\(\\alpha\\)=0.05. Іншими словами, можна сказати що різниця між нульовою гіпотезою та даними вибірки не є статистично значущою. Тобто наші дані не підтверджують гіпотезу, що рівень народжуваності у перші два тижні серпня 1966 відрізняється від звичного. Тобто, відсутність електроенергії не мало впливу на рівень народжуваності. тестування гіпотез для пропорцій Чи відрізняється відсоток новонароджених хлопчиків від 50%? У вибірці 200 новонароджених, з них 96 хлопчики. \\(H_0: p = 0.5\\) \\(H_A: p \\neq 0.5\\) Рівень довіри \\(\\alpha = 0.05\\) Тестова статистика \\[ z = \\frac{\\bar p - p}{\\sqrt{\\frac{p(1-p)}{n}}}\\] \\(\\bar p = \\frac{96}{200} = 0.48\\), p = 0.5, n = 200 \\(z = \\frac{\\bar p - p}{\\sqrt{\\frac{p(1-p)}{n}}} = \\frac{0.48 - 0.5}{\\sqrt{\\frac{0.5(1-0.5)}{200}}} = -0.566\\) ggplot(data.frame(x = c(-3,3)), aes(x)) + geom_vline(xintercept = 0.566, linetype=2, colour=&quot;blue&quot;) + geom_vline(xintercept = -0.566, linetype=2, colour=&quot;blue&quot;) + stat_function(fun = dnorm, colour=&quot;blue&quot;) + geom_area(stat = &quot;function&quot;, fun = dnorm, fill = &quot;lightblue&quot;, xlim = c(0.566, 3)) + geom_area(stat = &quot;function&quot;, fun = dnorm, fill = &quot;lightblue&quot;, xlim = c(-3, -0.566)) p.val = 2*pnorm(-0.566) p.val = 0.571 трактування результатів Для кількості новонароджених p-значення = 0.571, що не дозволяє відкинути нульову гіпотезу для рівня значущості \\(\\alpha = 0.05\\) Іншими словами, можна сказати що різниця між нульовою гіпотезою та даними вибірки не є статистично значущою. Тобто наші дані не підтверджують гіпотезу, що відсоток хлопчиків серед новонароджених відрізняється від 50%. "],
["confidenceinterval.html", "Розділ 7 Довірчий інтервал 7.1 Тестування гіпотез для середнього значення 7.2 інший підхід 7.3 Тестування гіпотез для пропорції 7.4 Покроковий план тестування гіпотез 7.5 Помилки І та ІІ типу", " Розділ 7 Довірчий інтервал Коли дослідники мають очікування щодо параметрів генеральної сукупності – говорять про статистичну гіпотезу. Зазвичай, гіпотеза формулюється як твердження що параметр генеральної сукупності має певне значення або знаходиться в певному інтервалі. Це твердження базується на попередніх дослідженнях та теорії. На основі інформації, отриманої з вибірки оцінюють, чи має сенс (справедливе) це твердження чи ні. Це те, що ми називаємо тест на значущість. Тест на значущість, як і побудова довірчих інтервалів, є методом вивідної статистики. Ми пробуємо оцінити параметри генеральної сукупності на основі вибірки. Тест на значущість базується на двох гіпотезах: це нульова та альтернативна гіпотези. Нульова гіпотеза позначається як \\(H_0\\), альтернативна як \\(H_A\\). Нульова гіпотеза стверджує, що параметр генеральної сукупності набирає конекретного значення. Ця гіпотеза може бути відхилена, якщо дані вибірки кажуть що це дуже нетипові очікування. Альтернативна гіпотеза стверджує, що параметр, який досліджується має альтернативне значення чи набір значень. Нульова та альтернативна гіпотези завжди взаємовиключні (mutually exclusive). Коли ви робите тест на значимість, то вважаєте, що нульова гіпотеза правдива поки дані вибірки не дадуть достатньо сильні аргументи, що це не так. Це схоже на суд присяжних. Прокурор пробує переконати суддів, що підсудний винен. Підсудний не має доводити свою невинність і вважається невинним, поки прокурор не доведе інакше. Як формулюються гіпотези? Нехай дослідження показало, що пульс студентів університету становить 70 ударів за хвилину. Середнє значення попередніх досліджень 72 удари за хвилину. Дослідник хоче визначити чи відрізняються результати вибірки від загальних результатів. Нульова гіпотеза \\(H_0: \\mu = 72\\) Альтернативна гіпотеза \\(H_A: \\mu \\neq 72\\). Тут маємо так звану двосторонню альтернативну гіпотезу. Ще можна перевіряти односторонні гіпотези: \\(H_A: \\mu &gt; 72\\) або \\(H_A: \\mu &lt; 72\\). 7.1 Тестування гіпотез для середнього значення Розглянемо тестування гіпотез для середнього значення на прикладі. 9 листопада 1965 року в енергосистемі США сталася аварія. 30 мільйонів людей протягом 13 годин перебували без світла. Це аварія відома як Northeast Blackout https://en.wikipedia.org/wiki/Northeast_blackout_of_1965 Через 9 місяців (10 серпня 1966) в NY Times опубліковане дослідження, яке стверджувало, що значно в Нью Йорку зросла народжуваність. Видання вважало причиною саме Northeast Blackout. Давайте проаналізуємо кількість новонароджених у перші два тижні серпня 1966 і визначимо, чи це значення статистично відрізняється від звичайного рівня народжуваності в Нью Йорку (середня кількість новонароджених на той час складала 430 на добу). \\(\\bar x = 432.21\\), s = 40.48 n = 14 Сформулюємо нульову гіпотезу: “Відключення електроенергії у листопаді 1965 року впливу на кількість новонароджених не має, тобто середнє значення таке ж, як і в інші місяці”. \\(H_0 = 430\\) (звична кількість новонароджених) Альтернативна гіпотеза: “Відключення електроенергії у листопаді 1965 має вплив на кількість новонароджених, тобто середнє значення відрізняєітся від 430”. \\(H_A \\neq 430\\) Це двостороння альтернатива, що означає що рівень народжуваності відрізняється. Можемо також розглядати односторонню альтернативу, наприклад \\(H_A &gt; 430\\). Тестова статистика вимірює різницю між даними отриманої вибірки та нульовою гіпотезою. Фактично тестова статистика відповідає на питання: “Яка відстань у середньоквадратичних відхиленнях між середнім значенням отриманої вибірки та середнім значенням згідно нульової гіпотези?” Обрахуємо тестову статистику для нашого прикладу. Для рівня народжуваності в Нью Йорку середнє значення вибірки \\(\\bar x\\) становить 432.21, а середнє значення генеральної сукупності \\(\\mu\\) згідно нульової гіпотези 430. Середньоквадратичне відхилення вибірки s = 40.48. Згідно центральної граничної теореми, середньоквадратичне відхилення відхилення вибіркового розподілу дорівнює \\(\\frac {\\sigma} {\\sqrt{n}}\\) і тестова статистика буде обчислюватись за формулою: \\[ Z = \\frac{\\bar X - \\mu_0}{\\frac{\\sigma}{\\sqrt{n}}}\\] Z – кількість середньоквадратичних відхилень між середнім значенням вибірки та середнього значення згідно нульової гіпотези Для обрахування тестової статистика Z потрібно знати середьноквадратичне відхилення генеральної сукупності \\(\\sigma\\) Як ми вже знаємо, можемо використати t-розподіл. Тобто потрібно обрахувати: \\[ t = \\frac{\\bar X - \\mu_0}{\\frac{s}{\\sqrt{n}}}\\] Для нашого прикладу середнє значення вибірки \\(\\bar x\\) 432.21, середнє значення згідно нульової гіпотези \\(\\mu_0\\) 430, середньоквадратичне відхилення вибірки s 40.48. Розмір вибірки n = 14. Тестова статистика: \\[ t = \\frac{\\bar X - \\mu_0}{\\frac{s}{\\sqrt{n}}} = \\frac{432.21 - 430}{\\frac{40.48}{\\sqrt{14}}} = 0.204\\] Тобто, середнє значення отриманої вибірки знаходиться на відстані 0.204 середньоквадратичних відхилень від середньоквадратичного значення нульової гіпотези. Чи ця різниця є статистично значимою? Чи можливо ми отримали це значення випадково? Оцінити це нам допоможе значення ймовірності або ж p-value. За припущення, що нульова гіпотеза правдива, p-value відповідає на питання “яка ймовірність отримати значення більш екстремальне ніж наще спостережуване середнє значення?” Чим менше p-value тим більш нереалістичною є нульова гіпотеза. Для нашого прикладу тестова статистика t = 0.204. За припущення що середнє значення нашої генеральної сукупності 430, яка ймовірність отримати вибірку, з t статистикою 0.204 або більш екстремальне? Так як ми працюємо з t-розподілом, то знайдемо кількість ступенів вільності: df = n - 1 = 13. Побудуємо наш t-розподіл з кількістю ступенів вільності df = 13 та зобразимо значення тестової статистики та площі під кривою: Ймовірність отримати таке значення t статистики, за умови, що середнє значення генеральної сукупності становить 430 можна обчислити за формулою (p_value): pt(0.204, df=13, lower.tail = FALSE) ## [1] 0.4207562 Однак, наша гіпотеза двостороння, тому графік буде виглядати так: а формула для обчислення p-value так: 2*pt(0.204, df=13, lower.tail = FALSE) ## [1] 0.8415124 Щоб визначити “статистичну значущість” ми порівнюємо отримане p-value з фіксованим значенням, яке є вирішальним наскільки ми маємо доказів, щоб відкинути нульову гіпотезу. Це вирішальне значення має назву рівень значущості та позначаєтся \\(\\alpha\\) Загально прийнятим \\(\\alpha\\) рівнем є \\(\\alpha =0.05\\). Це означає, що докази які ми отримали проти нульової гіпотези настільки сильні, що можуть бути отримані в результаті випадкового збігу не більше ніж в 5% (якщо нульова гіпотеза справедлива). Якщо p-value менше ніж \\(\\alpha\\) говорять, що різниця статистично значима для рівня \\(\\alpha\\). Тобто, для нашого прикладу, де Гіпотези: \\(H_0: \\mu = 430\\) \\(H_A: \\mu \\neq 430\\) Тестова статистика: \\[t = \\frac{\\bar X - \\mu_0}{\\frac{s}{\\sqrt{n}}} = \\frac{432.21 - 430}{\\frac{40.48}{\\sqrt{14}}} = 0.204\\] Ймовірність отримати таку тестову статистику p-value - 0.841. Порівняємо \\(\\alpha = 0.05\\) та p-value = 0.841. p_value &gt; \\(\\alpha\\) Це означає, що для кількості новонароджених у Нью Йорку p-vlaue = 0.814, що не дозволяє відкинути нульову гіпотезу для рівня значущості \\(\\alpha\\)=0.05. Іншими словами, можна сказати що різниця між нульовою гіпотезою та даними вибірки не є статистично значущою. Тобто наші дані не підтверджують гіпотезу, що рівень народжуваності у перші два тижні серпня 1966 відрізняється від звичного. Тобто, відсутність електроенергії не мало впливу на рівень народжуваності. В R є вбудований функціонал для проведення тесту на значущість. Це функція t-test. Наша вибірка за перші чотирнадцять днів серпня: newborns &lt;- c(452, 470, 431, 448, 467, 377, 344, 449, 440, 457, 471, 463, 405, 377) Використаємо функцію t-test, в якості параметрів вкажемо alternative = &quot;two.sided&quot; - оскільки розглядаємо двосторонню альтернативу, mu=430 - значення середнього для генеральної сукупності згідно нульової гіпотези та рівень значущості conf.level = 0.95: t.test(newborns, alternative = &quot;two.sided&quot;, mu=430, conf.level = 0.95) ## ## One Sample t-test ## ## data: newborns ## t = 0.20464, df = 13, p-value = 0.841 ## alternative hypothesis: true mean is not equal to 430 ## 95 percent confidence interval: ## 408.8384 455.5901 ## sample estimates: ## mean of x ## 432.2143 Бачимо, що виведення тесту на значущість включає також довірчий інтервал для цих даних. Який зв’язок між тестом на значущість та довірчим інтервалом? Твердження “P-значення для двостороннього тесту ≤ 0.05” еквівалентне “95% довірчий інтервал не містить \\(H_0\\) значення”, відповідно “P-значення для двостороннього тесту &gt; 0.05” еквівалентне “95% довірчий інтервал буде містити \\(H_0\\) значення”. У прикладі вище p-value = 0.841 &gt; \\(\\alpha\\), довірчий інтервал для рівня довіри 95% [408.8384, 455.5901] містить значення \\(H_0 = 430\\). 7.2 інший підхід Знайти критичні значення для заданого \\(\\alpha\\), зобразити критичні області. Якщо тестова статистика вибірки потрапляє в критичну область - можемо відхилити нульову гіпотезу. plot will be here 7.3 Тестування гіпотез для пропорції Розглянемо приклад тестування гіпотез для пропорції: Чи відрізняється відсоток новонароджених хлопчиків від 50%? У вибірці 200 новонароджених, з них 96 хлопчики. \\(H_0: p = 0.5\\) \\(H_A: p \\neq 0.5\\) Рівень довіри \\(\\alpha = 0.05\\) Тестова статистика: \\[ z = \\frac{\\bar p - p}{\\sqrt{\\frac{p(1-p)}{n}}}\\] \\(\\bar p = \\frac{96}{200} = 0.48\\), p = 0.5, n = 200 \\(z = \\frac{\\bar p - p}{\\sqrt{\\frac{p(1-p)}{n}}} = \\frac{0.48 - 0.5}{\\sqrt{\\frac{0.5(1-0.5)}{200}}} = -0.566\\) Зобразимо області під кривою для z-статистики (вони симетричні, оскільки використовуємо двосторонню гіпотезу): Для кількості новонароджених p-value = 0.571, що не дозволяє відкинути нульову гіпотезу для рівня значущості \\(\\alpha = 0.05\\) Іншими словами, можна сказати що різниця між нульовою гіпотезою та даними вибірки не є статистично значущою. Тобто наші дані не підтверджують гіпотезу, що відсоток хлопчиків серед новонароджених відрізняється від 50%. В R для тестування гіпотези про значення пропорції можна використовувати функцію prop.test з параметрами alternative = &quot;two.sided&quot; (може бути ще less або greater для односторонніх альтернатив) та correct = FALSE (correct=TRUE означає застосування Yates’ continuity correction http://www.statisticshowto.com/what-is-the-yates-correction/) prop.test(96, 200, alternative = &quot;two.sided&quot;, correct = FALSE) ## ## 1-sample proportions test without continuity correction ## ## data: 96 out of 200, null probability 0.5 ## X-squared = 0.32, df = 1, p-value = 0.5716 ## alternative hypothesis: true p is not equal to 0.5 ## 95 percent confidence interval: ## 0.4117917 0.5489621 ## sample estimates: ## p ## 0.48 Як бачимо, довірчий інтервал для рівня надійності 95% [0.4117917, 0.5489621] включає значення \\(H_0\\) 7.4 Покроковий план тестування гіпотез 7.5 Помилки І та ІІ типу При тестуванні тесту на значущість можна отримати помилку двох типів: помилика І типу, коли ми відхиляємо правдиву нульову гіпотезу (і, відповідно, приймаємо хибну альтернативну) помилка ІІ типу, коли ми не можемо відхилити хибну нульову гіпотезу Тобто при тестуванні гіпотез маємо чотири можливі наслідки: _ \\(H_0\\) правдива \\(H_0\\) хибна Приймаємо \\(H_0\\) Правильне рішення Помилка ІІ типу Відкидаємо \\(H_0\\) Помилка І типу Правильне рішення Помилка першого типу еквівалентна так званим false positives. Приклад помилки першого типу. Нехай досліджуємо ліки проти певної хвороби. Нульова гіпотеза стверджує, що ці ліки не чинять ніякого впливу на перебіг хвороби. Якщо ми відкидаємо правдиву нульову гіпотезу (робимо помилку І типу), і приймаємо хибну альтерантивну,тобто вважаємо, що використання цих ліків впливає на перебіг хвороби (що, насправді, не так). При збільшенні рівня довіри з 95% до 99% ми зменшуємо ймовірність зробити помилку І типу \\(\\alpha\\) (тобто відхилити правдиву нульову гіпотезу) з 5% до 1%. Однак, тут є інша небезпека: при цьому збільшується ймовірність зробити помилку ІІ типу. Помилка типу ІІ еквівалентна false negatives. У випадку з ліками не можемо відхилити хибну нульову гіпотезу, тобто вважаємо, що ліки не допомагають, однак, насправді, це не так і хворому могло б значно покращати. Ймовірніть зробити помилку ІІ типу позначається як \\(\\beta\\). \\(1-\\beta\\) - потужність критерію. Ще одне пояснення можна переглянути тут: http://www.slideshare.net/smulford/type-1-and-type-2-errors "]
]
